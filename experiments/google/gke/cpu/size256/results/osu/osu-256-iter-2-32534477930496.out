205.229s: job.exception type=cancel severity=0 interrupted by ctrl-C
205.442s: job.exception type=cancel severity=0 interrupted by ctrl-C
flux-job: task(s) exited with exit code 143

# OSU MPI Allreduce Latency Test v5.8
# Size       Avg Latency(us)
4                   20099.63
8                   19893.51
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
otherwise exiting without calling MPI_FINALIZE first).
--------------------------------------------------------------------------
otherwise exiting without calling MPI_FINALIZE first).
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
An MPI communication peer process has unexpectedly disconnected.  This
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This


An MPI communication peer process has unexpectedly disconnected.  This
otherwise exiting without calling MPI_FINALIZE first).
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This
otherwise exiting without calling MPI_FINALIZE first).
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This
Although this local MPI process will likely now behave unpredictably

otherwise exiting without calling MPI_FINALIZE first).
usually indicates a failure in the peer process (e.g., a crash or

--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This

--------------------------------------------------------------------------

usually indicates a failure in the peer process (e.g., a crash or
An MPI communication peer process has unexpectedly disconnected.  This
(it may even hang or crash), the root cause of this problem is the
An MPI communication peer process has unexpectedly disconnected.  This

--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably

An MPI communication peer process has unexpectedly disconnected.  This
Although this local MPI process will likely now behave unpredictably
--------------------------------------------------------------------------
(it may even hang or crash), the root cause of this problem is the

usually indicates a failure in the peer process (e.g., a crash or
failure of the peer -- that is what you need to investigate.  For
--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
usually indicates a failure in the peer process (e.g., a crash or
(it may even hang or crash), the root cause of this problem is the
--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
(it may even hang or crash), the root cause of this problem is the
--------------------------------------------------------------------------
(it may even hang or crash), the root cause of this problem is the
usually indicates a failure in the peer process (e.g., a crash or
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
failure of the peer -- that is what you need to investigate.  For
usually indicates a failure in the peer process (e.g., a crash or
failure of the peer -- that is what you need to investigate.  For
--------------------------------------------------------------------------
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
failure of the peer -- that is what you need to investigate.  For
--------------------------------------------------------------------------
(it may even hang or crash), the root cause of this problem is the
usually indicates a failure in the peer process (e.g., a crash or
generally: such peer hangups are frequently caused by application bugs
--------------------------------------------------------------------------
failure of the peer -- that is what you need to investigate.  For
usually indicates a failure in the peer process (e.g., a crash or
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
An MPI communication peer process has unexpectedly disconnected.  This
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
--------------------------------------------------------------------------
failure of the peer -- that is what you need to investigate.  For
usually indicates a failure in the peer process (e.g., a crash or
or other external events.
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
--------------------------------------------------------------------------
failure of the peer -- that is what you need to investigate.  For
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
usually indicates a failure in the peer process (e.g., a crash or
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More

otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
An MPI communication peer process has unexpectedly disconnected.  This
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
An MPI communication peer process has unexpectedly disconnected.  This
generally: such peer hangups are frequently caused by application bugs
otherwise exiting without calling MPI_FINALIZE first).

An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
example, there may be a core file that you can examine.  More
otherwise exiting without calling MPI_FINALIZE first).
or other external events.
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This

--------------------------------------------------------------------------
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
otherwise exiting without calling MPI_FINALIZE first).
or other external events.
An MPI communication peer process has unexpectedly disconnected.  This
otherwise exiting without calling MPI_FINALIZE first).
Although this local MPI process will likely now behave unpredictably
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
An MPI communication peer process has unexpectedly disconnected.  This
generally: such peer hangups are frequently caused by application bugs

  Local host: flux-sample-237
An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
(it may even hang or crash), the root cause of this problem is the
An MPI communication peer process has unexpectedly disconnected.  This
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
or other external events.
otherwise exiting without calling MPI_FINALIZE first).

An MPI communication peer process has unexpectedly disconnected.  This

failure of the peer -- that is what you need to investigate.  For
usually indicates a failure in the peer process (e.g., a crash or
otherwise exiting without calling MPI_FINALIZE first).
An MPI communication peer process has unexpectedly disconnected.  This
generally: such peer hangups are frequently caused by application bugs
otherwise exiting without calling MPI_FINALIZE first).

An MPI communication peer process has unexpectedly disconnected.  This
otherwise exiting without calling MPI_FINALIZE first).
example, there may be a core file that you can examine.  More
An MPI communication peer process has unexpectedly disconnected.  This

An MPI communication peer process has unexpectedly disconnected.  This
generally: such peer hangups are frequently caused by application bugs
usually indicates a failure in the peer process (e.g., a crash or
  Local PID:  289
An MPI communication peer process has unexpectedly disconnected.  This
Although this local MPI process will likely now behave unpredictably
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
An MPI communication peer process has unexpectedly disconnected.  This
or other external events.
otherwise exiting without calling MPI_FINALIZE first).
  Local host: flux-sample-237
An MPI communication peer process has unexpectedly disconnected.  This

or other external events.
(it may even hang or crash), the root cause of this problem is the
An MPI communication peer process has unexpectedly disconnected.  This

Although this local MPI process will likely now behave unpredictably

  Local host: flux-sample-237
An MPI communication peer process has unexpectedly disconnected.  This

failure of the peer -- that is what you need to investigate.  For
An MPI communication peer process has unexpectedly disconnected.  This
or other external events.

  Peer host:  flux-sample-0
An MPI communication peer process has unexpectedly disconnected.  This
  Local host: flux-sample-252
example, there may be a core file that you can examine.  More
An MPI communication peer process has unexpectedly disconnected.  This
or other external events.

  Local PID:  271
usually indicates a failure in the peer process (e.g., a crash or
  Local PID:  191
usually indicates a failure in the peer process (e.g., a crash or


  Local PID:  265
otherwise exiting without calling MPI_FINALIZE first).
  Peer host:  flux-sample-0
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
  Local host: flux-sample-183

--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
Although this local MPI process will likely now behave unpredictably

Although this local MPI process will likely now behave unpredictably
  Peer host:  flux-sample-0
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
failure of the peer -- that is what you need to investigate.  For
generally: such peer hangups are frequently caused by application bugs


  Peer host:  flux-sample-0
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
(it may even hang or crash), the root cause of this problem is the
or other external events.
  Local host: flux-sample-183

--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
example, there may be a core file that you can examine.  More

  Local PID:  263
otherwise exiting without calling MPI_FINALIZE first).
--------------------------------------------------------------------------
usually indicates a failure in the peer process (e.g., a crash or
failure of the peer -- that is what you need to investigate.  For
  Local host: flux-sample-238
  Local host: flux-sample-183

usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
generally: such peer hangups are frequently caused by application bugs
  Local PID:  208
  Local host: flux-sample-183
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
otherwise exiting without calling MPI_FINALIZE first).
example, there may be a core file that you can examine.  More
  Peer host:  flux-sample-0
  Local PID:  271
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or
or other external events.
--------------------------------------------------------------------------
  Peer host:  flux-sample-0
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
  Local PID:  206
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
usually indicates a failure in the peer process (e.g., a crash or

  Local PID:  199
Although this local MPI process will likely now behave unpredictably
usually indicates a failure in the peer process (e.g., a crash or
or other external events.
  Peer host:  flux-sample-0
(it may even hang or crash), the root cause of this problem is the
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably

  Peer host:  flux-sample-0
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
usually indicates a failure in the peer process (e.g., a crash or
  Peer host:  flux-sample-0

otherwise exiting without calling MPI_FINALIZE first).
  Local host: flux-sample-251
--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).

--------------------------------------------------------------------------
Although this local MPI process will likely now behave unpredictably
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
--------------------------------------------------------------------------
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).

(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
Although this local MPI process will likely now behave unpredictably
failure of the peer -- that is what you need to investigate.  For
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
Although this local MPI process will likely now behave unpredictably

(it may even hang or crash), the root cause of this problem is the
Although this local MPI process will likely now behave unpredictably
failure of the peer -- that is what you need to investigate.  For

usually indicates a failure in the peer process (e.g., a crash or
failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For

example, there may be a core file that you can examine.  More

failure of the peer -- that is what you need to investigate.  For

otherwise exiting without calling MPI_FINALIZE first).
failure of the peer -- that is what you need to investigate.  For

(it may even hang or crash), the root cause of this problem is the


failure of the peer -- that is what you need to investigate.  For

example, there may be a core file that you can examine.  More

  Local PID:  247
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
  Local host: flux-sample-251
example, there may be a core file that you can examine.  More
(it may even hang or crash), the root cause of this problem is the
otherwise exiting without calling MPI_FINALIZE first).
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
failure of the peer -- that is what you need to investigate.  For
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
otherwise exiting without calling MPI_FINALIZE first).
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
generally: such peer hangups are frequently caused by application bugs
failure of the peer -- that is what you need to investigate.  For
generally: such peer hangups are frequently caused by application bugs
(it may even hang or crash), the root cause of this problem is the
example, there may be a core file that you can examine.  More
(it may even hang or crash), the root cause of this problem is the
generally: such peer hangups are frequently caused by application bugs
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the

(it may even hang or crash), the root cause of this problem is the
failure of the peer -- that is what you need to investigate.  For
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the
generally: such peer hangups are frequently caused by application bugs
failure of the peer -- that is what you need to investigate.  For

or other external events.
example, there may be a core file that you can examine.  More

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For
(it may even hang or crash), the root cause of this problem is the

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For
  Local host: flux-sample-219
failure of the peer -- that is what you need to investigate.  For
  Peer host:  flux-sample-0

failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For
or other external events.
failure of the peer -- that is what you need to investigate.  For
failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For
  Local host: flux-sample-219
failure of the peer -- that is what you need to investigate.  For
otherwise exiting without calling MPI_FINALIZE first).
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More
  Local host: flux-sample-219
generally: such peer hangups are frequently caused by application bugs
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More
  Local PID:  239
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More
  Local PID:  247
example, there may be a core file that you can examine.  More
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More

example, there may be a core file that you can examine.  More
  Local host: flux-sample-219
example, there may be a core file that you can examine.  More
  Local PID:  279
example, there may be a core file that you can examine.  More
  Local PID:  271
example, there may be a core file that you can examine.  More
failure of the peer -- that is what you need to investigate.  For
example, there may be a core file that you can examine.  More
  Local PID:  255
example, there may be a core file that you can examine.  More
failure of the peer -- that is what you need to investigate.  For
  Local PID:  253
example, there may be a core file that you can examine.  More
example, there may be a core file that you can examine.  More
  Local PID:  249
generally: such peer hangups are frequently caused by application bugs
example, there may be a core file that you can examine.  More
  Peer host:  flux-sample-0
or other external events.
generally: such peer hangups are frequently caused by application bugs
  Local PID:  245
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
  Local PID:  241
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
  Local host: flux-sample-219
generally: such peer hangups are frequently caused by application bugs
or other external events.
  Local PID:  237
generally: such peer hangups are frequently caused by application bugs
or other external events.
  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs
or other external events.
  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs

  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs

  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs

  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs

  Local host: flux-sample-109
--------------------------------------------------------------------------
generally: such peer hangups are frequently caused by application bugs
  Local host: flux-sample-109
  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
  Local host: flux-sample-109
  Peer host:  flux-sample-0
or other external events.
  Local PID:  323
  Local PID:  239

  Local PID:  319
  Peer host:  flux-sample-0
or other external events.

  Local PID:  315
--------------------------------------------------------------------------
or other external events.
example, there may be a core file that you can examine.  More
  Peer host:  flux-sample-0
--------------------------------------------------------------------------
or other external events.

generally: such peer hangups are frequently caused by application bugs
or other external events.
or other external events.
--------------------------------------------------------------------------
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
--------------------------------------------------------------------------

or other external events.

--------------------------------------------------------------------------
--------------------------------------------------------------------------
  Local host: flux-sample-255
or other external events.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
  Local PID:  200
or other external events.

--------------------------------------------------------------------------
--------------------------------------------------------------------------
  Peer host:  flux-sample-0
or other external events.

  Peer host:  flux-sample-0
--------------------------------------------------------------------------
or other external events.
Although this local MPI process will likely now behave unpredictably
--------------------------------------------------------------------------
or other external events.


or other external events.
Although this local MPI process will likely now behave unpredictably
--------------------------------------------------------------------------

Although this local MPI process will likely now behave unpredictably

  Local host: flux-sample-110
Although this local MPI process will likely now behave unpredictably


(it may even hang or crash), the root cause of this problem is the

(it may even hang or crash), the root cause of this problem is the

(it may even hang or crash), the root cause of this problem is the
(it may even hang or crash), the root cause of this problem is the

failure of the peer -- that is what you need to investigate.  For
failure of the peer -- that is what you need to investigate.  For
failure of the peer -- that is what you need to investigate.  For

failure of the peer -- that is what you need to investigate.  For

example, there may be a core file that you can examine.  More

example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably

  Peer host:  flux-sample-0
example, there may be a core file that you can examine.  More
(it may even hang or crash), the root cause of this problem is the

--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
Although this local MPI process will likely now behave unpredictably

--------------------------------------------------------------------------
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably

generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
  Local host: flux-sample-110
generally: such peer hangups are frequently caused by application bugs
Although this local MPI process will likely now behave unpredictably
  Local PID:  240
  Local host: flux-sample-110
or other external events.
Although this local MPI process will likely now behave unpredictably
  Local host: flux-sample-110
(it may even hang or crash), the root cause of this problem is the
or other external events.
  Local host: flux-sample-110
failure of the peer -- that is what you need to investigate.  For
or other external events.
(it may even hang or crash), the root cause of this problem is the
or other external events.
(it may even hang or crash), the root cause of this problem is the

  Local host: flux-sample-110
(it may even hang or crash), the root cause of this problem is the

  Local host: flux-sample-110
(it may even hang or crash), the root cause of this problem is the

(it may even hang or crash), the root cause of this problem is the

  Local host: flux-sample-110
(it may even hang or crash), the root cause of this problem is the
  Local host: flux-sample-254
  Local host: flux-sample-110
failure of the peer -- that is what you need to investigate.  For
  Local host: flux-sample-254
  Local host: flux-sample-110
example, there may be a core file that you can examine.  More
  Local host: flux-sample-254
  Local host: flux-sample-110
failure of the peer -- that is what you need to investigate.  For
  Local host: flux-sample-254
  Local host: flux-sample-110
failure of the peer -- that is what you need to investigate.  For
  Local PID:  279
  Local host: flux-sample-110
failure of the peer -- that is what you need to investigate.  For
  Local PID:  249
failure of the peer -- that is what you need to investigate.  For
  Local PID:  287
failure of the peer -- that is what you need to investigate.  For
  Local PID:  281
failure of the peer -- that is what you need to investigate.  For
  Peer host:  flux-sample-0
example, there may be a core file that you can examine.  More
  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs
  Peer host:  flux-sample-0
example, there may be a core file that you can examine.  More
  Peer host:  flux-sample-0
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
--------------------------------------------------------------------------
example, there may be a core file that you can examine.  More
generally: such peer hangups are frequently caused by application bugs
  Local PID:  257
or other external events.
  Peer host:  flux-sample-0
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
generally: such peer hangups are frequently caused by application bugs
  Local PID:  233
generally: such peer hangups are frequently caused by application bugs
  Local PID:  231
or other external events.

  Local PID:  229
or other external events.
or other external events.
  Local PID:  225
or other external events.
or other external events.
or other external events.
or other external events.

  Local host: flux-sample-220
  Local PID:  216

  Local PID:  214




  Local PID:  201

  Local PID:  199
  Local host: flux-sample-220
  Local PID:  193
  Local PID:  204
  Local PID:  188
  Local host: flux-sample-220
  Local host: flux-sample-220
  Local host: flux-sample-220
  Local PID:  184
  Local host: flux-sample-220
  Local host: flux-sample-220
  Local host: flux-sample-220
  Local PID:  201
  Peer host:  flux-sample-0
  Local PID:  188
  Peer host:  flux-sample-0
  Local PID:  196
  Local PID:  193
  Local PID:  207
  Local PID:  199
  Local PID:  190
  Peer host:  flux-sample-0
--------------------------------------------------------------------------
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
  Peer host:  flux-sample-0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
START OF JOBSPEC
{"resources": [{"type": "node", "count": 256, "with": [{"type": "slot", "count": 56, "with": [{"type": "core", "count": 1}], "label": "task"}]}], "tasks": [{"command": ["/opt/osu-benchmark/build.openmpi/mpi/collective/osu_allreduce"], "slot": "task", "count": {"per_slot": 1}}], "attributes": {"system": {"duration": 0, "cwd": "/opt", "shell": {"options": {"rlimit": {"cpu": -1, "fsize": -1, "data": -1, "stack": 8388608, "core": -1, "nofile": 1048576, "as": -1, "rss": -1, "nproc": -1}, "cpu-affinity": "per-task"}}}, "user": {"study_id": "osu-256-iter-2"}}, "version": 1}
START OF EVENTLOG
{"timestamp":1724464006.5508199,"name":"init"}
{"timestamp":1724464006.5526159,"name":"starting"}
{"timestamp":1724464006.686208,"name":"shell.init","context":{"service":"0-shell-fFjdHQXYj","leader-rank":0,"size":256}}
{"timestamp":1724464006.8579481,"name":"shell.start","context":{"taskmap":{"version":1,"map":[[0,256,56,1]]}}}
{"timestamp":1724464211.9008048,"name":"shell.task-exit","context":{"localid":9,"rank":9,"state":"Exited","pid":424,"wait_status":15,"signaled":15,"exitcode":143}}
{"timestamp":1724464212.7111123,"name":"complete","context":{"status":36608}}
{"timestamp":1724464212.7111487,"name":"done"}

