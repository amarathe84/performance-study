blueprint_name: performance-study

# IMPORTANT:
# In the compute group, you likely want to:
# 1. uncomment the bandwidth tier (done)
# 2. set placement to true
# 3. set some min instances so our entire cluster is up when it comes up (otherwise you wait)
# 4. Make the disk size larger
# 5. Possibly build a VM that pulls all our Singularity containers

vars:
  project_id:  converged-computing
  dynamic_nodes_max: 32
  deployment_name: performance-study
  compute_machine_type: c2d-standard-112
  region: us-central1
  zone: us-central1-c
  custom_image:
    family: apptainer-enabled
    project: $(vars.project_id)
  disk_size: 256

# Documentation for each of the modules used below can be found at
# https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/main/modules/README.md

deployment_groups:
- group: primary
  modules:
  - id: network
    source: modules/network/vpc

  - id: scripts_for_image
    source: modules/scripts/startup-script
    settings:
      runners:
      - type: shell
        destination: install_apptainer.sh
        content: |
          #!/bin/sh
          dnf install -y epel-release
          dnf install -y apptainer

- group: packer
  modules:
  - id: apptainer-enabled-image
    source: modules/packer/custom-image
    kind: packer
    use:
    - network
    - scripts_for_image
    settings:
      source_image_project_id: [schedmd-slurm-public]
      # see latest in https://github.com/GoogleCloudPlatform/slurm-gcp/blob/master/docs/images.md#published-image-family
      source_image_family: slurm-gcp-6-6-hpc-rocky-linux-8
      # You can find size of source image by using following command
      # gcloud compute images describe-from-family <source_image_family> --project schedmd-slurm-public
      disk_size: $(vars.disk_size)
      image_family: $(vars.custom_image.family)
      state_timeout: 15m

- group: cluster
  modules:
  - id: compute_nodeset
    source: community/modules/compute/schedmd-slurm-gcp-v6-nodeset
    use: [network]
    settings:
      node_count_dynamic_max: $(vars.dynamic_nodes_max)
      disk_size_gb: $(vars.disk_size)
      instance_image: $(vars.custom_image)
      machine_type: $(vars.compute_machine_type)
      instance_image_custom: true
      bandwidth_tier: gvnic_enabled
      allow_automatic_updates: false

  - id: nfs
    source: community/modules/file-system/nfs-server
    use: [network]
    settings:
      local_mounts: [/home, /apps]

  - id: compute_partition
    source: community/modules/compute/schedmd-slurm-gcp-v6-partition
    use: [compute_nodeset]
    settings:
      partition_name: compute
      is_default: true

  - id: slurm_login
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-login
    use: [network]
    settings:
      name_prefix: login
      enable_login_public_ips: true
      disk_size_gb: $(vars.disk_size)
      instance_image: $(vars.custom_image)
      instance_image_custom: true

  - id: slurm_controller
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-controller
    use:
    - network
    - compute_partition
    - slurm_login
    - nfs
    settings:
      enable_controller_public_ips: true
      disk_size_gb: $(vars.disk_size)
      instance_image: $(vars.custom_image)
      instance_image_custom: true
