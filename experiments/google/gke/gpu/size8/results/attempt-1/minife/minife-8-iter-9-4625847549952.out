69.642s: job.exception type=exec severity=0 rank 15 exited and exit-timeout=30s has expired
flux-job: task(s) exited with exit code 139
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-0
  System call: unlink(2) /tmp/ompi.flux-sample-0.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-0
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-0:00696] WARNING: common_sm_module_unlink failed.
[flux-sample-0:00696] WARNING: common_sm_module_unlink failed.
[flux-sample-0:00696] WARNING: /tmp/ompi.flux-sample-0.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-0 unlink failed.
[flux-sample-0:00696] WARNING: /tmp/ompi.flux-sample-0.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-0 unlink failed.
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-1
  System call: unlink(2) /tmp/ompi.flux-sample-1.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-1
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-1:00569] WARNING: common_sm_module_unlink failed.
[flux-sample-1:00569] WARNING: common_sm_module_unlink failed.
[flux-sample-1:00569] WARNING: /tmp/ompi.flux-sample-1.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-1 unlink failed.
[flux-sample-1:00569] WARNING: /tmp/ompi.flux-sample-1.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-1 unlink failed.
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-2
  System call: unlink(2) /tmp/ompi.flux-sample-2.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-2
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-2:00569] WARNING: common_sm_module_unlink failed.
[flux-sample-2:00569] WARNING: common_sm_module_unlink failed.
[flux-sample-2:00569] WARNING: /tmp/ompi.flux-sample-2.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-2 unlink failed.
[flux-sample-2:00569] WARNING: /tmp/ompi.flux-sample-2.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-2 unlink failed.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A system call failed during sm BTL initialization that should
A system call failed during sm BTL initialization that should
not have.  It is likely that your MPI job will now either abort or
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.
experience performance degradation.


  System call: open(2)
  System call: open(2)
  Error:       No such file or directory (errno 2)
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-3
  System call: open(2) 
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-3:00570] sm_segment_attach: mca_common_sm_module_attach failure!
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-3
  System call: unlink(2) /tmp/ompi.flux-sample-3.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-3
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-3:00569] WARNING: common_sm_module_unlink failed.
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
[flux-sample-3:00569] WARNING: common_sm_module_unlink failed.
[flux-sample-3:00569] WARNING: /tmp/ompi.flux-sample-3.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-3 unlink failed.
experience performance degradation.
[flux-sample-3:00569] WARNING: /tmp/ompi.flux-sample-3.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-3 unlink failed.

  Local host:  flux-sample-5
  System call: unlink(2) /tmp/ompi.flux-sample-5.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-5
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-5:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-5:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-5:00533] WARNING: /tmp/ompi.flux-sample-5.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-5 unlink failed.
[flux-sample-5:00533] WARNING: /tmp/ompi.flux-sample-5.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-5 unlink failed.
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-6
  System call: unlink(2) /tmp/ompi.flux-sample-6.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-6
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-6:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-6:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-6:00533] WARNING: /tmp/ompi.flux-sample-6.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-6 unlink failed.
[flux-sample-6:00533] WARNING: /tmp/ompi.flux-sample-6.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-6 unlink failed.
--------------------------------------------------------------------------
A system call failed during shared memory initialization that should
not have.  It is likely that your MPI job will now either abort or
experience performance degradation.

  Local host:  flux-sample-7
  System call: unlink(2) /tmp/ompi.flux-sample-7.0/jf.0/0/shared_mem_cuda_btl_module.flux-sample-7
  Error:       No such file or directory (errno 2)
--------------------------------------------------------------------------
[flux-sample-7:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-7:00533] WARNING: common_sm_module_unlink failed.
[flux-sample-7:00533] WARNING: /tmp/ompi.flux-sample-7.0/jf.0/0/shared_mem_cuda_pool_rndv.flux-sample-7 unlink failed.
[flux-sample-7:00533] WARNING: /tmp/ompi.flux-sample-7.0/jf.0/0/shared_mem_cuda_btl_rndv.flux-sample-7 unlink failed.
[flux-sample-2:00570] *** Process received signal ***
[flux-sample-2:00569] *** Process received signal ***
[flux-sample-2:00569] Signal: Segmentation fault (11)
[flux-sample-2:00569] Signal code: Address not mapped (1)
[flux-sample-2:00569] Failing at address: 0x78b8a05475cc
[flux-sample-2:00569] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7aa60b9ed520]
[flux-sample-2:00569] [ 1] /usr/local/pancakes/lib/openmpi/mca_btl_smcuda.so(mca_btl_smcuda_component_progress+0x101)[0x7aa60177f981]
[flux-sample-2:00569] [ 2] /usr/local/pancakes/lib/libopen-pal.so.40(opal_progress+0x34)[0x7aa60b922104]
[flux-sample-2:00569] [ 3] /usr/local/pancakes/lib/libmpi.so.40(ompi_request_default_wait+0x55)[0x7aa60c325545]
[flux-sample-2:00569] [ 4] /usr/local/pancakes/lib/libmpi.so.40(ompi_coll_base_bcast_intra_generic+0x65e)[0x7aa60c379f7e]
[flux-sample-2:00569] [ 5] /usr/local/pancakes/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_bcast_intra_dec_fixed+0x40)[0x7aa601384840]
[flux-sample-2:00569] [ 6] /usr/local/pancakes/lib/libmpi.so.40(MPI_Bcast+0x120)[0x7aa60c33cd00]
[flux-sample-2:00569] [ 7] miniFE.x(+0x380a0)[0x5aac188ac0a0]
[flux-sample-2:00569] [ 8] miniFE.x(+0x10690)[0x5aac18884690]
[flux-sample-2:00569] [ 9] /lib/x86_64-linux-gnu/libc.so.6(+0x29d90)[0x7aa60b9d4d90]
[flux-sample-2:00569] [10] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80)[0x7aa60b9d4e40]
[flux-sample-2:00569] [11] miniFE.x(+0x10e45)[0x5aac18884e45]
[flux-sample-2:00569] *** End of error message ***
[flux-sample-2:00570] Signal: Segmentation fault (11)
[flux-sample-7:00534] *** Process received signal ***
[flux-sample-2:00570] Signal code: Address not mapped (1)
[flux-sample-7:00534] Signal: Segmentation fault (11)
[flux-sample-2:00570] Failing at address: 0x7bd6e05488cc
[flux-sample-7:00534] Signal code: Address not mapped (1)
[flux-sample-7:00534] Failing at address: 0x7f4d2812bf4c
[flux-sample-7:00534] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x799b4e7ed520]
[flux-sample-7:00534] [ 1] /usr/local/pancakes/lib/openmpi/mca_btl_smcuda.so(mca_btl_smcuda_component_progress+0x101)[0x799b44574981]
[flux-sample-7:00534] [ 2] /usr/local/pancakes/lib/libopen-pal.so.40(opal_progress+0x34)[0x799b4e722104]
[flux-sample-2:00570] [flux-sample-7:00534] [ 3] /usr/local/pancakes/lib/libmpi.so.40(ompi_request_default_wait+0x55)[0x799b4f11a545]
[flux-sample-7:00534] [ 4] /usr/local/pancakes/lib/libmpi.so.40(ompi_coll_base_bcast_intra_generic+0x5ea)[0x799b4f16ef0a]
[flux-sample-7:00534] [ 5] /usr/local/pancakes/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_bcast_intra_dec_fixed+0x40)[0x799b44179840]
[ 0] [flux-sample-7:00534] [ 6] /usr/local/pancakes/lib/libmpi.so.40(MPI_Bcast+0x120)[0x799b4f131d00]
[flux-sample-7:00534] [ 7] miniFE.x(+0x380a0)[0x59bd794df0a0]
[flux-sample-7:00534] [ 8] miniFE.x(+0x10690)[0x59bd794b7690]
[flux-sample-7:00534] [ 9] /lib/x86_64-linux-gnu/libc.so.6(+0x29d90)[0x799b4e7d4d90]
[flux-sample-7:00534] [10] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80)[0x799b4e7d4e40]
/lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7805275ed520]
[flux-sample-7:00534] [11] miniFE.x(+0x10e45)[0x59bd794b7e45]
[flux-sample-7:00534] *** End of error message ***
[flux-sample-2:00570] [ 1] /usr/local/pancakes/lib/openmpi/mca_btl_smcuda.so(mca_btl_smcuda_component_progress+0x101)[0x78051d23a981]
[flux-sample-2:00570] [ 2] /usr/local/pancakes/lib/libopen-pal.so.40(opal_progress+0x34)[0x780527463104]
[flux-sample-2:00570] [ 3] /usr/local/pancakes/lib/libmpi.so.40(ompi_request_default_wait+0x55)[0x780527de2545]
[flux-sample-2:00570] [ 4] /usr/local/pancakes/lib/libmpi.so.40(ompi_coll_base_bcast_intra_generic+0x5ea)[0x780527e36f0a]
[flux-sample-2:00570] [ 5] /usr/local/pancakes/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_bcast_intra_dec_fixed+0x40)[0x78051ce3f840]
[flux-sample-2:00570] [ 6] /usr/local/pancakes/lib/libmpi.so.40(MPI_Bcast+0x120)[0x780527df9d00]
[flux-sample-2:00570] [ 7] miniFE.x(+0x380a0)[0x5881bfab60a0]
[flux-sample-2:00570] [ 8] miniFE.x(+0x10690)[0x5881bfa8e690]
[flux-sample-2:00570] [ 9] /lib/x86_64-linux-gnu/libc.so.6(+0x29d90)[0x7805275d4d90]
[flux-sample-2:00570] [10] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80)[0x7805275d4e40]
[flux-sample-2:00570] [11] miniFE.x(+0x10e45)[0x5881bfa8ee45]
[flux-sample-2:00570] *** End of error message ***
[flux-sample-6][[0,0],12][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(46) failed: Connection reset by peer (104)
[flux-sample-0][[0,0],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(44) failed: Connection reset by peer (104)
[flux-sample-0:00696] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-0:00696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[flux-sample-1:00569] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-1:00569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[flux-sample-5:00533] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-3:00569] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-5:00533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[flux-sample-3:00569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[flux-sample-6:00533] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-6:00533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[flux-sample-7:00533] 1 more process has sent help message help-opal-shmem-mmap.txt / sys call fail
[flux-sample-7:00533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
69.641s: flux-shell[0]: FATAL: doom: rank 15 exited and exit-timeout=30s has expired
START OF JOBSPEC
{"resources": [{"type": "node", "count": 8, "with": [{"type": "slot", "count": 2, "with": [{"type": "core", "count": 1}, {"type": "gpu", "count": 1}], "label": "task"}]}], "tasks": [{"command": ["miniFE.x", "nx=230", "ny=230", "nz=230", "num_devices=8", "use_locking=1", "elem_group_size=10", "use_elem_mat_fields=300", "verify_solution=0"], "slot": "task", "count": {"per_slot": 1}}], "attributes": {"system": {"duration": 0, "cwd": "/opt/minife", "shell": {"options": {"rlimit": {"cpu": -1, "fsize": -1, "data": -1, "stack": 8388608, "core": -1, "nofile": 1048576, "as": -1, "rss": -1, "nproc": -1}, "cpu-affinity": "per-task", "gpu-affinity": "per-task"}}}, "user": {"study_id": "minife-8-iter-9"}}, "version": 1}
START OF EVENTLOG
{"timestamp":1724744815.4618912,"name":"init"}
{"timestamp":1724744815.4631526,"name":"starting"}
{"timestamp":1724744815.4810967,"name":"shell.init","context":{"service":"0-shell-f36WmJqVZ","leader-rank":0,"size":8}}
{"timestamp":1724744815.498997,"name":"shell.start","context":{"taskmap":{"version":1,"map":[[0,8,2,1]]}}}
{"timestamp":1724744820.6680951,"name":"shell.task-exit","context":{"localid":1,"rank":15,"state":"Exited","pid":534,"wait_status":139,"signaled":11,"exitcode":139}}
{"timestamp":1724744855.8311059,"name":"complete","context":{"status":35584}}
{"timestamp":1724744855.8311341,"name":"done"}

