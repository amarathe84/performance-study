advancedMachineFeatures:
  threadsPerCore: 1
cpuPlatform: Intel Haswell
creationTimestamp: '2024-08-30T08:07:56.560-07:00'
deletionProtection: false
disks:
- architecture: X86_64
  autoDelete: true
  boot: true
  deviceName: persistent-disk-0
  diskSizeGb: '100'
  guestOsFeatures:
  - type: SEV_SNP_CAPABLE
  - type: IDPF
  - type: SEV_LIVE_MIGRATABLE
  - type: SECURE_BOOT
  - type: UEFI_COMPATIBLE
  - type: GVNIC
  - type: SEV_CAPABLE
  - type: SEV_LIVE_MIGRATABLE_V2
  - type: VIRTIO_SCSI_MULTIQUEUE
  index: 0
  interface: SCSI
  kind: compute#attachedDisk
  licenses:
  - https://www.googleapis.com/compute/v1/projects/cos-cloud/global/licenses/cos-pcid
  - https://www.googleapis.com/compute/v1/projects/gke-node-images/global/licenses/gke-node
  - https://www.googleapis.com/compute/v1/projects/cos-cloud-shielded/global/licenses/shielded-cos
  - https://www.googleapis.com/compute/v1/projects/cos-cloud/global/licenses/cos
  mode: READ_WRITE
  shieldedInstanceInitialState:
    dbs:
    - content: MIIEDTCCAvWgAwIBAgIQRtEbux4j2WDjYimBMkIBYjANBgkqhkiG9w0BAQsFADCBizELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMRgwFgYDVQQDEw9VRUZJIERCIEtleSB2MTAwHhcNMjAwODA2MTk0ODU1WhcNMzAwODA0MTk0ODU1WjCBizELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMRgwFgYDVQQDEw9VRUZJIERCIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDQzJHu5A61uBNU6UUUZ5MiXjXwy8Du44BHhisNBpi6cTVHZddJ85iNldE5cPL7hZFJP9n77KyFRCCLxT2CVDNkwMyE2jvJkTz2x2qWvJ-uIuL25Asfgbrv7t1h2Jn790ZLwb9U3qQvqMLvIh_cTtNLat0DaZJsdnJo1MTnFAWrYZZ19KB4j6JJpG_QBnQ-s8XibeSSoa_bMEQTn2OEQFeEcume3CeuZKzXyytMLKkV_z4z-CYddyRwkOFivWUHWq2nVecQQgdyDNWYxGnY4MNsTMYFfv-mhyRzMwhxBFMwMAaEwhTFWsIP6VNwrwIgQaDw3o1fUEuzavTfdNhULaJLAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEIEtOsnFY2N1KW7dg9Wd_GEcIwV_a-U2DCn5ZyUsGWickMCsGA1UdIwQkMCKAIEtOsnFY2N1KW7dg9Wd_GEcIwV_a-U2DCn5ZyUsGWickMA0GCSqGSIb3DQEBCwUAA4IBAQCOd9V3WYv589dVov5ZOYo4zSs5PXpts1_8sYvMwvzLBr46LaejfG7KjjIY665Cnik__Zy9N3ZS9-fEeGKrBPE8ClwC06QhLbWDSFIqj2y9qq5FyBW0k1no2UQBnvx4CnLw_BgU3eae0wjv1lpDIbMwxe3E_aucVmzaIX3O83cw2JL9lLm1Psum0L2VHDZSCTP24vzrWoXXo4USHO_tBt_NkYrdkQH5CqGJYtxzKRwHHKEar3vzsiW4DPzlW8kUjRual1eBOKT5YKGbrOA_PJXV9x_7v1f2uAIrqh3HyppDTaGJ7Lux1MDf_hKuwAFI5QJTy9NEojbuUk1tzB4ys_W8
      fileType: X509
    dbxs:
    - content: MIIEaDCCA1CgAwIBAgIJAKqfsrCdjyCoMA0GCSqGSIb3DQEBCwUAMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEUMBIGA1UECxMLQ2hyb21pdW0gT1MxFzAVBgNVBAMTDlVFRkkgREIgS2V5IHYxMB4XDTE4MTIwODAxMTk0MVoXDTI4MTIwNTAxMTk0MVowfzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEXMBUGA1UEAxMOVUVGSSBEQiBLZXkgdjEwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCtZ9U4P5aWlBwiTocmkUjOn2XpvHUlUOnsnhvsm994hAb0MNk2d3fXa8Nz14v9JiBTSf70KU2Zhxb_bSN3KAIv-f7F2AuXte7U9SnzZ02UDmK4TU1bFQW67Y3Gc2hWprCHYEjiRQD4J3WPWhuZnAXqzXQk3uDWVPETi-G9KAM1R-yNxZfoEjfIKhLabDsWqDtnMSovObLoVfwTdnm0WCuYTFtY_CKNxuxeKuzDsC5Su9N3dSFbpGhXJjwUaXPLWY5MFIqIQNBfhmWzDd4PItXaXV3V44IqWTXclE2aSUqkwNrEZ1cRpHG4PYM1aHVmjcO_dWlvthcepTIMIEMAXg2LAgMBAAGjgeYwgeMwHQYDVR0OBBYEFNXbmmdkM0aIsPMyEIv25JRaOPA-MIGzBgNVHSMEgaswgaiAFNXbmmdkM0aIsPMyEIv25JRaOPA-oYGEpIGBMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEUMBIGA1UECxMLQ2hyb21pdW0gT1MxFzAVBgNVBAMTDlVFRkkgREIgS2V5IHYxggkAqp-ysJ2PIKgwDAYDVR0TBAUwAwEB_zANBgkqhkiG9w0BAQsFAAOCAQEAJ2vbNymAKTUbRvxnAohHozVUByrKHCq1o8b-bKrgv7Ch0X4itfG8Uwvt0xG7CTpl_Dno92MtpOpFv4ydqox-pP1kTsRcnFNggndXdjpGILIB94KmFiYJvB6RzocJsXsXBa0tULOR24qiB9f93kfITS7Ec60WjFfpgYKEnuEgcV0yBuZzAZbxo1uF4n1hhmVUnKtEI9pX-8geYIIqIYiwwT2jnhFogWw4PeSyg-HMR1CLwwJeH2XDa924LpgHFuR-AbikipAE2vIE0yqJzo0o4tn9-sRuMaQcZ4VQqIzMiniW5H7nGeoQY3ktHX5eq6x-4jFvdLnzzq_D4sS-UWHzOA==
      fileType: X509
    - content: MIIEiTCCA3GgAwIBAgIJAOzm3xz71Vu6MA0GCSqGSIb3DQEBCwUAMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEUMBIGA1UEChMLR29vZ2xlIExMQy4xFDASBgNVBAsTC0Nocm9taXVtIE9TMSEwHwYDVQQDExhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwHhcNMTgxMjA4MDExOTQwWhcNMjgxMjA1MDExOTQwWjCBiTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEhMB8GA1UEAxMYVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwg5hvVH6fJSBNji7ynBl1SQzWceL5P3ul6RcB-1s5wXqzXlIHiyRqBdj4hj2pLzpKJGmXWnerIwJOkdsFg7IwZpA4xHE1F-M8XlpuuUn_Xdfccef36ddZEUH6QLwNm96T89F4ujt0omJ-0GV37vBsxEY-hwR3O8XBgyx8TvvYxNnVyTgi19qQdb2ES8-yWJkebdzgugcmNf9K-55fnEiyxWtrvEQb2sowWIS3-b1I_BP85pW2pldh9yQWfb3OY2NJhGSbQSnLi3J0IhRXROEtAXCU4MLTq2cHOpGX0DtJP_g_jD1pnC1O6CCZgVycK4DgZXeDzOG_2Uimhr0y1rcewIDAQABo4HxMIHuMB0GA1UdDgQWBBQEqlpkrYWCzJe69eMUdF1byztBmzCBvgYDVR0jBIG2MIGzgBQEqlpkrYWCzJe69eMUdF1byztBm6GBj6SBjDCBiTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEhMB8GA1UEAxMYVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxggkA7ObfHPvVW7owDAYDVR0TBAUwAwEB_zANBgkqhkiG9w0BAQsFAAOCAQEAWsd3mq0dADTD7Tx2uYcDeJcJHO0x91hO26p2cqUSox4wPgc4_xk5yiteMgDB5CWLwgcuneDAYYMO1PmktpEvLu9a82gCGxGiww-w78OJTOrs68VM1zB0jqA3X5EyVSwVJqi8idgrnnGsJAcSBosnUI8pNi9SDC3MRPE1q1EUjuDNjsE7t_ItBe-MSMWCH2hpG8unZ7uwWCRfAV3Fkdnq_S5HzDy6-kKyGdj-rprhVeDz2xSyMOlNIJig4uuqU166DTfoQA2TxnMG_TuHt69Z4uZcVwx_HwPs2-vUCCYqZDwuuHKNIEm8kIK8sSPSsp22sC8h-7Klb8wj_d0lzShgkg==
      fileType: X509
    - content: MIID0zCCArugAwIBAgIJANuXsNG_1HHxMA0GCSqGSIb3DQEBCwUAMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRYwFAYDVQQHDA1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKDAtHb29nbGUgTExDLjEUMBIGA1UECwwLQ2hyb21pdW0gT1MxFzAVBgNVBAMMDlVFRkkgREIgS2V5IHYxMCAXDTE4MDQyNzE1MDYzN1oYDzIyMTgwMzEwMTUwNjM3WjB_MQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMRcwFQYDVQQDDA5VRUZJIERCIEtleSB2MTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALWzFg8obysKXCjnbBTpAM8dMFC2pHX7GpwESNG-FYQI218Y1Ao1p5BttGqPoU5lGNeYUXxgxIqfN18ALHH10gRCRfqbC54faPU1lMr0e0jvi67GgGztyLl4ltAgK7HHTHmtZwghYNS45pKz_LFGm-TlKg-HPZBFT9GtbjRZe5IS2xdKkWM_sPA8qXwzvqmLN3OQckf0KchSUQmB3-wh4vYFV2TEjz10oR0FZO8LFFOOeooukcRDYy219XrdM21APnfszHmfKhzAFddOcYdwKwOL-w9TKVUwCIM70GL_YOtywA17mQkEm0ON79oyQ0daDlZ0ngDxC8xUIASYsRRPOkkCAwEAAaNQME4wHQYDVR0OBBYEFFO6MYgG9CvYp6qAqn_Jm-MANGpvMB8GA1UdIwQYMBaAFFO6MYgG9CvYp6qAqn_Jm-MANGpvMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAIGyOB_3oFo6f3WoFrdBzimb_weH8hejtCggpcL-8Wdex9VRl5MKi_1GlGbietMDsr1alwdaagam9RafuIQplohTSBnQrU-u-LbtRlCF9C25GDQ70S0QlxAQmt41Sc7kSFTPm6BHauF3b_Raf9AX30MamptoXoAhgMnHAitCn6yCOsRJ_d1t04lqsiqefhf26xItvRnkuxG7-IQnbyGFCGPcjFNAE1thLpL_6y_dprVwTLsvZnsWYj-1Gg1yUkOnCN8Kl3Q3RDVqo98mORUc0bKB-B8_FQsbtmzbb-29nXQJW1FJx0ejqJyDGGBPHAGpwEJTVB3mwWXzBU6Ny7T3dlk=
      fileType: X509
    - content: MIID6TCCAtGgAwIBAgIJAKgdcZ45rGMDMA0GCSqGSIb3DQEBCwUAMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMSEwHwYDVQQDDBhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwIBcNMTgwNDI3MTUwNjM3WhgPMjIxODAzMTAxNTA2MzdaMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMSEwHwYDVQQDDBhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCbIdHPMQZZU68jI5kz5rmwvo-DQZZJ5amRnAUnBpNllhNQB6TaLUS_D9TIo_0X1e8T21Xk4Pf3D5ckbuQxsJzQ5OVEOb59sJ9AhjVUoxQxuVW-iBzD0mWbxKf2cASy2YRIEcaAAI5QT2SwO8gZy_G8LwAk-vO0vIbynN0WuFLl1Dp2cMQ3CxLSPH-QPSZyGd6o6ewUU9JzboppujXpk43EQH5ZJE_wJb_ujUFWcFzKHb_EkV1hI1TmBJ1-vR2kao4_1hQO6k1zLUR-MyBHY0SRU2OQxBpSez-qt7oItMBc1EanXvq9tqx0ndCTmXQYQplT5wtkPbE9sd5zwbDt8btHAgMBAAGjUDBOMB0GA1UdDgQWBBS5Tmmv3JM8w1mfP9V5xAIdjBhb7TAfBgNVHSMEGDAWgBS5Tmmv3JM8w1mfP9V5xAIdjBhb7TAMBgNVHRMEBTADAQH_MA0GCSqGSIb3DQEBCwUAA4IBAQB9BRTP37ik4jF2BmJJspMA6NHS7mxIckFCYKl-TO8zGFd3mlA6dnEw5WY-tUcBNJpAaHNJV_rzagGPpWMIoy-nAaLSSpnyhEXYTnQvzejYRijN3N0V9tmM0qgViHNBqTxdfcwlst5OUesGHPqgBOt5RRu5OGJ0rkuymWwxHOKIw43hz5FW7vhumbtJ3iy8HSFQIjSYMkr0sOzJhmvnHlpZ4pOoPNyNA9DM6smriH-2-MnJFM9w8bg6zsV5X-6KL464_FuXL_X_IWmAsAbi8Ge8ZMJjEaDrF1qkD4aLvu0MshzEdvrvQO-3Gn3Lmi_RYKR0HKZp7jXTySj76sxt9QK4
      fileType: X509
    keks:
    - content: MIIEIjCCAwqgAwIBAgIRAKxVeWkn5a0pF1C0o_HUM6owDQYJKoZIhvcNAQELBQAwgZUxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEfMB0GA1UECxMWQ29udGFpbmVyIE9wdGltaXplZCBPUzEiMCAGA1UEAxMZVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxMDAeFw0yMDA4MDYxOTQ4NTBaFw0zMDA4MDQxOTQ4NTBaMIGVMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEUMBIGA1UEChMLR29vZ2xlIExMQy4xHzAdBgNVBAsTFkNvbnRhaW5lciBPcHRpbWl6ZWQgT1MxIjAgBgNVBAMTGVVFRkkgS2V5IEV4Y2hhbmdlIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC6ZCJ4Oldm1z3gwwAjWqiHRMFrXPwq0XmVmLWoaGUBzeL41VwHK76iQTxl11HYhqaAr_0nmVQAM3M6so6cmydd7l1RPYJpZ3Shy3qO4xxgy30kp4zW00m9EVEdkmh9-9zi_G89uutz7wOb34M2Wrybwa7D5U102DmSoJAoq5z2YrvpjZoGLRGqBBP6A1l-_gRGMAgUMqKbhD1HF1VKXZnIGq9UJcpHhRvQxOG3nlVWk6z8dH-Rnp_9YfEPRORAUF5PUnUL5-I3wr5derIIoeYxc7G2ZuTyRWsF9WVyZ7OquYwxAY4l4xkDJpAvSomHkbfNgtCZyTm2pMIkRou0up5lAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEINDkWV5HwgIi6aogGQUbZwWC5Es_Vx9SX5kG8i1xiXxKMCsGA1UdIwQkMCKAINDkWV5HwgIi6aogGQUbZwWC5Es_Vx9SX5kG8i1xiXxKMA0GCSqGSIb3DQEBCwUAA4IBAQCOTmuK7QQ4sP_8qYI2-bkvbQg1Vpq0W_aWtm0AQDw2iEVgfIq8JxNHu61ZhkmBiEhsdaaj7bYt_8owpvxfRnmzMPhQ6iB51vkExjWipD9spgSb8tfp0te6MqTT3omyYI9x4L13wn9ufZtlhZXlVgbjUN1QyevHwNt7Kms8Nd9Jbk9JCV9JoOIjkBpUjpCWCDfdGDD-iGIPzGdS-KjrNiA4udnzkdkO83dFMMvu69a1snCRUshNvHBNPbPRwbRYV9lS_QTwfft7EgbNF0455gblZbejvGJgR1Vhyen0jIPouVWxXe0X7AnGK8Mc3DUQBPVGT4ZR0WChbcwiOavh2t2X
      fileType: X509
    pk:
      content: MIIEGTCCAwGgAwIBAgIQYB8C9RH--O1hXkpp2FVSXjANBgkqhkiG9w0BAQsFADCBkTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMR4wHAYDVQQDExVVRUZJIFBsYXRmb3JtIEtleSB2MTAwHhcNMjAwODA2MTk0ODQ0WhcNMzAwODA0MTk0ODQ0WjCBkTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMR4wHAYDVQQDExVVRUZJIFBsYXRmb3JtIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQClSQ15LUf193eJfM6b5etGgz8auvdI72Cclo3fHvwXBzsm5T1QamwYAqrCTcS7MxauCTkmkXTS9ejM4NNpQWF6KG82nR88vRyKO_MnSNL8ZP-rtRu0p1X_mUYXwi0_nPkyPKLR2QJ9H2EOrw_RChWvwnu281WtfUPCYs2t2SjBCF_mgzZI8o3s8wOtL8y-Dmi9T0bGO1wYX2okz51PKbhgVGQA7KJRmeekIxEkiN7GOb_2VQqcdM9c846OlC-8abwgDvrL3YqKqhw8DnSM2AbNpZIgUTd1Ut3X-PWXVKBj3qdxjAyRez8dPWymXDji-CBoBzLsWEkUW87S1coggOABAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEIMk0-K2sxOjtSpl-2pXmBWwwvSMGEIThmdDsSxQk2XZQMCsGA1UdIwQkMCKAIMk0-K2sxOjtSpl-2pXmBWwwvSMGEIThmdDsSxQk2XZQMA0GCSqGSIb3DQEBCwUAA4IBAQA7Pmaixb0FuDtpesNGvaBkTGWWMO7bDtx4rQom7zprEnliFJZung08FS3r73ob1urH0lzZm9022nRp8xqcSGk3wDkE9xQppWhvjhf6SOHdwM9_OxVq6no_BPz1PkRYsg4V07cgYPCtp7Ck7ZBI7m3MbLUyg8EG14_tvjKX9Xh2h0FSGuGg8_jjGYCGDtaSPkXBpAWurZ5mC2o9CzGaBJR4f_51I5C2AfHMG0H5T0Kehuyb_IzX9mAwArGmt62e4T9SxdP7LZUNPMEzOrhW1RzXvsD6Vod4uA9h2n_lbZHiBBExM2PMwuoobb-io-W0ARL4OCN5jah0a7q1ax6UYJK-
      fileType: X509
  source: https://www.googleapis.com/compute/v1/projects/converged-computing/zones/us-central1-a/disks/gke-gpu-cluster-16-default-pool-b92275cf-glwr
  type: PERSISTENT
fingerprint: QVOLpiXnziE=
guestAccelerators:
- acceleratorCount: 8
  acceleratorType: https://www.googleapis.com/compute/v1/projects/converged-computing/zones/us-central1-a/acceleratorTypes/nvidia-tesla-v100
id: '7678686927389482660'
kind: compute#instance
labelFingerprint: HvZPXrFVWdE=
labels:
  goog-gke-cost-management: ''
  goog-gke-node: ''
  goog-k8s-cluster-location: us-central1-a
  goog-k8s-cluster-name: gpu-cluster-16
  goog-k8s-node-pool-name: default-pool
lastStartTimestamp: '2024-08-30T08:09:15.210-07:00'
machineType: https://www.googleapis.com/compute/v1/projects/converged-computing/zones/us-central1-a/machineTypes/n1-standard-32
metadata:
  fingerprint: k_uovea1SDM=
  items:
  - key: instance-template
    value: projects/248370210276/global/instanceTemplates/gke-gpu-cluster-16-default-pool-b92275cf
  - key: created-by
    value: projects/248370210276/zones/us-central1-a/instanceGroupManagers/gke-gpu-cluster-16-default-pool-b92275cf-grp
  - key: serial-port-logging-enable
    value: 'true'
  - key: kube-labels
    value: cloud.google.com/gke-accelerator=nvidia-tesla-v100,cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=32,cloud.google.com/gke-gpu-driver-version=latest,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=n1,cloud.google.com/private-node=false
  - key: google-compute-enable-pcid
    value: 'true'
  - key: kubelet-config
    value: |
      apiVersion: kubelet.config.k8s.io/v1beta1
      authentication:
        anonymous:
          enabled: false
        webhook:
          enabled: true
        x509:
          clientCAFile: /etc/srv/kubernetes/pki/ca-certificates.crt
      authorization:
        mode: Webhook
      cgroupRoot: /
      clusterDNS:
      - 34.118.224.10
      clusterDomain: cluster.local
      cpuManagerPolicy: static
      enableDebuggingHandlers: true
      evictionHard:
        memory.available: 100Mi
        nodefs.available: 10%
        nodefs.inodesFree: 5%
        pid.available: 10%
      featureGates:
        DisableKubeletCloudCredentialProviders: true
        ExecProbeTimeout: false
        GracefulNodeShutdown: true
        InTreePluginAWSUnregister: true
        InTreePluginAzureDiskUnregister: true
        InTreePluginvSphereUnregister: true
        RotateKubeletServerCertificate: true
      kernelMemcgNotification: true
      kind: KubeletConfiguration
      kubeReserved:
        cpu: 110m
        ephemeral-storage: 41Gi
        memory: 9012Mi
      maxParallelImagePulls: 3
      readOnlyPort: 10255
      serializeImagePulls: false
      serverTLSBootstrap: true
      shutdownGracePeriod: 30s
      shutdownGracePeriodCriticalPods: 15s
      staticPodPath: /etc/kubernetes/manifests
  - key: cluster-name
    value: gpu-cluster-16
  - key: kubeconfig
    value: |
      apiVersion: v1
      kind: Config
      clusters:
      - cluster:
          server: https://10.128.0.68
          certificate-authority: '/etc/srv/kubernetes/pki/ca-certificates.crt'
        name: default-cluster
      contexts:
      - context:
          cluster: default-cluster
          namespace: default
          user: exec-plugin-auth
        name: default-context
      current-context: default-context
      users:
      - name: exec-plugin-auth
        user:
          exec:
            apiVersion: "client.authentication.k8s.io/v1beta1"
            command: '/home/kubernetes/bin/gke-exec-auth-plugin'
            args: ["--cache-dir", '/var/lib/kubelet/pki/']
  - key: gci-update-strategy
    value: update_disabled
  - key: gci-metrics-enabled
    value: 'true'
  - key: configure-sh
    value: |
      #!/usr/bin/env bash

      # Copyright 2016 The Kubernetes Authors.
      #
      # Licensed under the Apache License, Version 2.0 (the "License");
      # you may not use this file except in compliance with the License.
      # You may obtain a copy of the License at
      #
      #     http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing, software
      # distributed under the License is distributed on an "AS IS" BASIS,
      # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      # See the License for the specific language governing permissions and
      # limitations under the License.

      # Due to the GCE custom metadata size limit, we split the entire script into two
      # files configure.sh and configure-helper.sh. The functionality of downloading
      # kubernetes configuration, manifests, docker images, and binary files are
      # put in configure.sh, which is uploaded via GCE custom metadata.

      set -o errexit
      set -o nounset
      set -o pipefail

      ### Hardcoded constants

      DEFAULT_CNI_VERSION='v1.3.0-gke.16'
      DEFAULT_CNI_HASH_LINUX_AMD64='55c9fe10c127b4a81318ae67fe758d455924915cc68b9f4cbd0fc71f0ca16dd9f272716a5dd3168baa1bab4df20b9c1775a17a4cd7756ec062c65939bef2451e'
      DEFAULT_CNI_HASH_LINUX_ARM64='7541e997da0a1ac8c5d3ee5bf36dcfcddf15e73d2f1056f45d76c0df058dbd54b6049a7cf928d26cde0b41c7cbffdc2a248f9360e1228ce3f40b75ad6366493e'

      DEFAULT_NPD_VERSION='v0.8.13-57-gc3c5389'
      DEFAULT_NPD_HASH_AMD64='2cb0f1610adb5d8d3c077d8ce7a65fb4066f419e82c3ed4ce72a7c4b337bcef7ab9e53d006d97bea70acd980565e2df80466858e6b5291cb1d10587bf0fb9d6c'
      DEFAULT_NPD_HASH_ARM64='e049d37298cbcb3479b3fdc2927ca169fdbe7661dc5c6b1f7cd8f9fb66634eb1c12858155b40f32f86262ebca1171061ce92a520668ce898f89936c668214207'

      NPD_CUSTOM_PLUGINS_VERSION="v1.0.15"
      NPD_CUSTOM_PLUGINS_TAR_AMD64_HASH="82f369538a1908649f8822e9a3207b351bd1102c411c56901808b90386f637e55da87955633b1a6156324a6aa25d8cf4a2b245099ff3721e16fd3c62bff7cc2b"
      NPD_CUSTOM_PLUGINS_TAR_ARM64_HASH="33a422187423dfb7eb32742158ec8f4357a14d612b7e98c991f86f50d737887a4c37aaadabd9db18aa20071cf0cd9809995cb2931c3d17d32bb23f0e3a3190bd"

      DEFAULT_CRICTL_VERSION='v1.28.0-gke.1'
      DEFAULT_CRICTL_AMD64_SHA512='46387d29d2d79efe0fc0b83df3de6f3d9b00d1477d9765cd8e9a5d30b234d6d9b5bfd408bf4f7741c75a7bc0163b362156475e941c6387476866f0e69bae6ce3'
      DEFAULT_CRICTL_ARM64_SHA512='bb6505766cd294905bad7c8af11133a8f712e1a6806cf39c6eadcfadb5fcd608efdbf8e2abdf21e5061b4ff3bc5778e76005da64f7d91f4b2e5c543ebd833b54'
      DEFAULT_MOUNTER_ROOTFS_VERSION='v1.0.0'
      DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512='631330b7fa911d67e400b1d014df65a7763667d4afd4ecefe11a4a89dc9b8be626e5610d53b536c255a3ab488408ab2da8a0699d9fdad280cb3aa24bc2f30ab0'
      DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512='83cf9ab7961627359654131abd2d4c4b72875d395c50cda9e417149b2eb53b784dfe5c2f744ddbccfe516e36dd64c716d69d161d8bc8b4f42a9207fe676d0bc1'

      RIPTIDE_FUSE_VERSION="v0.196.1.patch"
      RIPTIDE_FUSE_ARM64_SHA512='ada069cdc325d73b61ee44539f4971ac143f9a310c422ce86c5a5c8c89f81526a002243cb4c3ccdae83e83af1082ac7321c6645bde4ea08b647bb4d18fac182e'
      RIPTIDE_FUSE_BIN_ARM64_SHA512='b3a1492b9da3f50972cc07a036653618496359a998dbf18441fb93654ab6e790c3a17bf769cc844696fd62c1f733e2606015c0c4163881cc7809b5b4d1726093'
      RIPTIDE_FUSE_AMD64_SHA512='678dd9991d1e71000e40e1c1b6f4d4ab6fbb9d1df05bdde6b1eee0837c992e295f95b507f9692f3d7215d100d4142dbc706bef0ade88aa364519797aff542cfa'
      RIPTIDE_FUSE_BIN_AMD64_SHA512='c7a70531104e6340ff7e2de591d7de67daf0b7e1931185ab2851df70646817b505e935859e1930576c52f7cc53e461f96c08c4a232f6cba157dda19e6ebdd556'

      RIPTIDE_SNAPSHOTTER_VERSION="v1.29-8"
      RIPTIDE_SNAPSHOTTER_SHA512='f74f13ed827dca8d7bd6f203cadcfe58184e7cf5a593b50676f537741db21c16edce05ac6958c18fdf1d836a6588fbbbb667a2c7cc7fbed71c952257c6552a1d'
      RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512='7da7744788e4b12daeaf8c713f4e190ed4d6d0682bc29d90f04fcee70d53109d0f823f23a37313446e562da46bb80ec1d8f3cb16857b107ba7f0f26c0af7557e'
      RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512='6678000d1273aa28075e6ff83c99d8e8f7016397814241e98c2d3300a2f73fec3f75f7f53dd6e9618974d9492ca64bdcf9c7dc4543f05834254cc9c160c51adb'

      AUTH_PROVIDER_GCP_VERSION="v0.0.2-gke.4"
      AUTH_PROVIDER_GCP_HASH_LINUX_AMD64="156058e5b3994cba91c23831774033e0d505d6d8b80f43541ef6af91b320fd9dfaabe42ec8a8887b51d87104c2b57e1eb895649d681575ffc80dd9aee8e563db"
      AUTH_PROVIDER_GCP_HASH_LINUX_ARM64="1aa3b0bea10a9755231989ffc150cbfa770f1d96932db7535473f7bfeb1108bafdae80202ae738d59495982512e716ff7366d5f414d0e76dd50519f98611f9ab"

      ###

      # Backend endpoints (configurable for TPC).
      # May be overridden when kube-env is sourced.
      #
      # NOTE: Endpoints should behave exactly like a GDU (Google Default Universe)
      # endpoint. E.g., An alternative `STORAGE_ENDPOINT` must have the same buckets
      # and paths as the `storage.googleapis.com` that this script depends on.
      STORAGE_ENDPOINT="${STORAGE_ENDPOINT:-https://storage.googleapis.com}"
      PGA_ENDPOINT="${PGA_ENDPOINT:-private.googleapis.com}"
      KUBE_DOCKER_REGISTRY="${KUBE_DOCKER_REGISTRY:-gke.gcr.io}"

      # Whether to configure private google access or not (defaults to true).
      # May be overridden when kube-env is sourced.
      CONFIGURE_PGA="${CONFIGURE_PGA:-true}"

      # Standard curl flags.
      CURL_FLAGS='--fail --silent --show-error --retry 5 --retry-delay 3 --connect-timeout 10 --retry-connrefused'

      # This version needs to be the same as in gke/cluster/gce/gci/configure-helper.sh
      GKE_CONTAINERD_INFRA_CONTAINER="pause:3.8@sha256:880e63f94b145e46f1b1082bb71b85e21f16b99b180b9996407d61240ceb9830"

      # Set max reboot retry 3 plus the inital boot count
      MAX_BOOT_COUNT="${MAX_BOOT_COUNT:-4}"

      function set-broken-motd {
        cat > /etc/motd <<EOF
      Broken (or in progress) Kubernetes node setup! Check the cluster initialization status
      using the following commands.

      Master instance:
        - sudo systemctl status kube-master-installation
        - sudo systemctl status kube-master-configuration

      Node instance:
        - sudo systemctl status kube-node-installation
        - sudo systemctl status kube-node-configuration
      EOF
      }

      # A function that fetches a GCE metadata value and echoes it out.
      # Args:
      #   $1 : URL path after /computeMetadata/v1/ (without heading slash).
      #   $2 : An optional default value to echo out if the fetch fails.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function get-metadata-value {
        local default="${2:-}"

        local status
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H 'Metadata-Flavor: Google' \
          "http://metadata/computeMetadata/v1/${1}" \
        || status="$?"
        status="${status:-0}"

        if [[ "${status}" -eq 0 || -z "${default}" ]]; then
          return "${status}"
        else
          echo "${default}"
        fi
      }

      # A function to fetch kube-env from GCE metadata server
      # or using hurl on the master if available
      function download-kube-env {
        (
          umask 077
          local kube_env_path="/tmp/kube-env.yaml"
          if [[ "$(is-master)" == "true" && $(use-hurl) = "true" ]]; then
            local kube_env_path="${KUBE_HOME}/kube-env.yaml"
            download-kube-env-hurl "${kube_env_path}"
          else
            local meta_path="http://metadata.google.internal/computeMetadata/v1/instance/attributes/kube-env"
            echo "Downloading kube-env via GCE metadata from ${meta_path} to ${kube_env_path}"
            # shellcheck disable=SC2086
            retry-forever 10 curl ${CURL_FLAGS} \
              -H "X-Google-Metadata-Request: True" \
              -o "${kube_env_path}" \
              "${meta_path}"
          fi

          # Convert the yaml format file into a shell-style file.
          eval "$(python3 -c '''
      import pipes,sys,yaml
      items = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()
      for k, v in items:
          print("readonly {var}={value}".format(var=k, value=pipes.quote(str(v))))
      ''' < "${kube_env_path}" > "${KUBE_HOME}/kube-env")"

          # Leave kube-env if we are a master
          if [[ "$(is-master)" != "true" ]]; then
            rm -f "${kube_env_path}"
          fi
        )
      }

      # A function to pull kube-env from HMS using hurl
      function download-kube-env-hurl {
        local -r kube_env_path="$1"
        local -r endpoint=$(get-metadata-value "instance/attributes/gke-api-endpoint")
        local -r kube_env_hms_path=$(get-metadata-value "instance/attributes/kube-env-path")

        echo "Downloading kube-env via hurl from ${kube_env_hms_path} to ${kube_env_path}"
        retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \
          --dst "${kube_env_path}" \
          "${kube_env_hms_path}"
        chmod 600 "${kube_env_path}"
      }

      function download-kubelet-config {
        local -r dest="$1"
        echo "Downloading Kubelet config file, if it exists"
        # Fetch kubelet config file from GCE metadata server.
        (
          umask 077
          local -r tmp_kubelet_config="/tmp/kubelet-config.yaml"
          # shellcheck disable=SC2086
          retry-forever 10 curl ${CURL_FLAGS} \
            -H "X-Google-Metadata-Request: True" \
            -o "${tmp_kubelet_config}" \
            http://metadata.google.internal/computeMetadata/v1/instance/attributes/kubelet-config
          # only write to the final location if curl succeeds
          mv "${tmp_kubelet_config}" "${dest}"
        )
      }

      # A function to pull kube-master-certs from HMS using hurl
      function download-kube-master-certs-hurl {
        local -r endpoint=$(get-metadata-value "instance/attributes/gke-api-endpoint")
        local -r tmp_kube_master_certs_path="/tmp/kube-master-certs.yaml"
        local -r kube_master_certs_path="${KUBE_HOME}/kube-master-certs"
        local -r kube_master_certs_hms_path=$(get-metadata-value "instance/attributes/kube-master-certs-path")

        echo "Downloading kube-master-certs via hurl from ${kube_master_certs_hms_path} to ${tmp_kube_master_certs_path}"
        retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \
          --dst "${tmp_kube_master_certs_path}" \
          "${kube_master_certs_hms_path}"

        # Convert the yaml format file into a shell-style file.
        eval "$(python3 -c '''
      import pipes,sys,yaml
      items = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()
      for k, v in items:
          print("readonly {var}={value}".format(var=k, value=pipes.quote(str(v))))
      ''' < "${tmp_kube_master_certs_path}" > "${kube_master_certs_path}")"

        # Remove the temp certs and strip perms for other users
        rm -f "${tmp_kube_master_certs_path}"
        chmod 600 "${kube_master_certs_path}"
      }

      function validate-hash {
        local -r file="$1"
        local -r expected="$2"

        actual_sha1=$(sha1sum "${file}" | awk '{ print $1 }') || true
        actual_sha512=$(sha512sum "${file}" | awk '{ print $1 }') || true
        if [[ "${actual_sha1}" != "${expected}" ]] && [[ "${actual_sha512}" != "${expected}" ]]; then
          echo "== ${file} corrupted, sha1 ${actual_sha1}/sha512 ${actual_sha512} doesn't match expected ${expected} =="
          return 1
        fi
      }

      # Get default service account credentials of the VM.
      GCE_METADATA_INTERNAL="http://metadata.google.internal/computeMetadata/v1/instance"
      function get-credentials {
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H "Metadata-Flavor: Google" \
          "${GCE_METADATA_INTERNAL}/service-accounts/default/token" \
        | python3 -c 'import sys; import json; print(json.loads(sys.stdin.read())["access_token"])'
      }

      function valid-storage-scope {
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H "Metadata-Flavor: Google" \
          "${GCE_METADATA_INTERNAL}/service-accounts/default/scopes" \
        | grep -E "auth/devstorage|auth/cloud-platform"
      }

      # Determine if this node is a master using metadata
      function is-master {
        local -r is_master_val=${KUBERNETES_MASTER:-$(get-metadata-value "instance/attributes/is-master-node")}
        local result="false"
        if [[ ${is_master_val:-} == "true" ]]; then
          result="true"
        fi
        echo $result
      }

      # A function that returns "true" if hurl should be used, "false" otherwise.
      function use-hurl {
        local -r enable_hms_read=${ENABLE_HMS_READ:-$(get-metadata-value "instance/attributes/enable_hms_read")}
        local result="false"

        if [[ -f "${KUBE_HOME}/bin/hurl" && "${enable_hms_read}" == "true" ]]; then
          result="true"
        fi
        echo $result
      }

      # Retry a download until we get it. Takes a hash and a set of URLs.
      #
      # $1 is the sha512/sha1 hash of the URL. Can be "" if the sha512/sha1 hash is unknown.
      # $2+ are the URLs to download.
      function download-or-bust {
        local -r hash="$1"
        shift 1

        while true; do
          for url in "$@"; do
            local file="${url##*/}"
            rm -f "${file}"
            # if the url belongs to GCS API we should use oauth2_token in the headers if the VM service account has storage scopes
            local curl_headers=""

            if [[ "$url" =~ ^${STORAGE_ENDPOINT}/.* ]] ; then
              local canUseCredentials=0

              echo "Getting the scope of service account configured for VM."
              if ! valid-storage-scope ; then
                canUseCredentials=1
                # this behavior is preserved for backward compatibility. We want to fail fast if SA is not available
                # and try to download without SA if scope does not exist on SA
                echo "No service account or service account without storage scope. Attempt to download without service account token."
              fi

              if [[ "${canUseCredentials}" == "0" ]] ; then
                echo "Getting the service account access token configured for VM."
                local access_token="";
                if access_token=$(get-credentials); then
                  echo "Service account access token is received. Downloading ${url} using this token."
                else
                  echo "Cannot get a service account token. Exiting."
                  exit 1
                fi

                curl_headers=${access_token:+Authorization: Bearer "${access_token}"}
              fi
            fi
            if ! curl ${curl_headers:+-H "${curl_headers}"} -f --ipv4 -Lo "${file}" --connect-timeout 20 --retry 6 --retry-delay 10 --retry-connrefused "${url}"; then
              echo "== Failed to download ${url}. Retrying. =="
            elif [[ -n "${hash}" ]] && ! validate-hash "${file}" "${hash}"; then
              echo "== Hash validation of ${url} failed. Retrying. =="
            else
              if [[ -n "${hash}" ]]; then
                echo "== Downloaded ${url} (HASH = ${hash}) =="
              else
                echo "== Downloaded ${url} =="
              fi
              return
            fi
          done
        done
      }

      function record-preload-info {
        echo "$1,$2" >> "${KUBE_HOME}/preload_info"
        echo "Recording preload info for ${1} ${2}"
      }

      function is-preloaded {
        local -r key=$1
        local -r value=$2
        grep -qs "${key},${value}" "${KUBE_HOME}/preload_info"
      }

      function is-ubuntu {
        [[ -f "/etc/os-release" && $(grep ^NAME= /etc/os-release) == 'NAME="Ubuntu"' ]]
      }

      function split-commas {
        echo -e "${1//,/'\n'}"
      }

      function remount-flexvolume-directory {
        local -r flexvolume_plugin_dir=$1
        mkdir -p "$flexvolume_plugin_dir"
        mount --bind "$flexvolume_plugin_dir" "$flexvolume_plugin_dir"
        mount -o remount,exec "$flexvolume_plugin_dir"
      }

      function install-gci-mounter-tools {
        CONTAINERIZED_MOUNTER_HOME="${KUBE_HOME}/containerized_mounter"
        if [[ -n "${MOUNTER_ROOTFS_VERSION:-}" ]]; then
            local -r mounter_rootfs_version="${MOUNTER_ROOTFS_VERSION}"
            local -r mounter_rootfs_tar_sha="${MOUNTER_ROOTFS_TAR_SHA512}"
        else
          local -r mounter_rootfs_version="${DEFAULT_MOUNTER_ROOTFS_VERSION}"
          case "${HOST_PLATFORM}/${HOST_ARCH}" in
            linux/amd64)
              local -r mounter_rootfs_tar_sha="${DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512}"
              ;;
            linux/arm64)
              local -r mounter_rootfs_tar_sha="${DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512}"
              ;;
            *)
              echo "Unrecognized version and platform/arch combination:"
              echo "$mounter_rootfs_version $HOST_PLATFORM/$HOST_ARCH"
              echo "Set MOUNTER_ROOTFS_VERSION and MOUNTER_ROOTFS_TAR_SHA512 to overwrite"
              exit 1
              ;;
          esac
        fi

        if is-preloaded "mounter" "${mounter_rootfs_tar_sha}"; then
          echo "mounter is preloaded."
          return
        fi

        echo "Downloading gci mounter tools."
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}"
        chmod a+x "${CONTAINERIZED_MOUNTER_HOME}"

        # Copy the mounter binary downloaded with the k8s binaries tar file
        cp "${KUBE_HOME}/kubernetes/server/bin/mounter" "${CONTAINERIZED_MOUNTER_HOME}/mounter"
        chmod a+x "${CONTAINERIZED_MOUNTER_HOME}/mounter"
        # Download the debian rootfs required for the mounter container
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}/rootfs"
        local -r mounter_rootfs_tar="containerized-mounter-${mounter_rootfs_version}_${HOST_PLATFORM}_${HOST_ARCH}.tar.gz"
        download-or-bust "${mounter_rootfs_tar_sha}" "${STORAGE_ENDPOINT}/gke-release/containerized-mounter/${mounter_rootfs_version}/${mounter_rootfs_tar}"
        mv "${KUBE_HOME}/${mounter_rootfs_tar}" "/tmp/${mounter_rootfs_tar}"
        tar xzf "/tmp/${mounter_rootfs_tar}" -C "${CONTAINERIZED_MOUNTER_HOME}/rootfs"
        rm "/tmp/${mounter_rootfs_tar}"
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}/rootfs/var/lib/kubelet"

        record-preload-info "mounter" "${mounter_rootfs_tar_sha}"
      }

      function docker-installed {
          if systemctl cat docker.service &> /dev/null ; then
              return 0
          else
              return 1
          fi
      }

      function disable_aufs() {
        # disable aufs module if aufs is loaded
        if lsmod | grep "aufs" &> /dev/null ; then
          sudo modprobe -r aufs
        fi
      }

      function detect_mtu {
        local MTU=1460
        if [[ "${DETECT_MTU:-}" == "true" ]];then
          local default_nic=$(ip route get 8.8.8.8 | sed -nr "s/.*dev ([^\ ]+).*/\1/p")
          if [ -f "/sys/class/net/$default_nic/mtu" ]; then
            MTU=$(cat /sys/class/net/$default_nic/mtu)
          fi
        fi
        echo $MTU
      }

      # This function cofigures docker. It has no conditional logic.
      # It will restart docker service so new settings will be picked up.
      # This method cannot be preloaded as the boot disk changes will not be persistet thru the reboots.
      function assemble-docker-flags {
        # log the contents of the /etc/docker/daemon.json if already exists
        if [ -f /etc/docker/daemon.json ]; then
          echo "Contents of the old docker config"
          cat /etc/docker/daemon.json
        fi

        disable_aufs

        # COS and Ubuntu have different docker options configured as command line arguments.
        # Use systemctl show docker to see the full list of options.
        # When configuring Docker options you can use daemon.json or command line arguments
        # The same option cannot be configured by both, even if it is a list option and can be repeated in the command line multiple times.
        # This is why we are not simply configuring everything in daemon.json.

        local MTU="$(detect_mtu)"

        # options to be set on COS, registry-mirror is pre-configured on COS
        local os_specific_options="\"live-restore\": true,\
         \"storage-driver\": \"overlay2\",\
         \"mtu\": ${MTU},"

        if is-ubuntu; then
          # Ubuntu already have everthing set
          os_specific_options=""
        fi

        # Important setting: set docker0 cidr to private ip address range to avoid conflict with cbr0 cidr range ("bip": "169.254.123.1/24")
        cat > /etc/docker/daemon.json <<EOF
      {
        "pidfile": "/var/run/docker.pid",
        "iptables": false,
        "ip-masq": false,
        "log-level": "warn",
        "bip": "169.254.123.1/24",
        "log-driver": "json-file",
        ${os_specific_options}
        "log-opts": {
            "max-size": "10m",
            "max-file": "5"
        }
      }
      EOF

        # Ensure TasksMax is sufficient for docker.
        # (https://github.com/kubernetes/kubernetes/issues/51977)
        echo "Extend the docker.service configuration to set a higher pids limit"
        mkdir -p /etc/systemd/system/docker.service.d
        cat <<EOF >/etc/systemd/system/docker.service.d/01tasksmax.conf
      [Service]
      TasksMax=infinity
      EOF

        # Do not move to the daemon.json file for backward compatibility.
        # Command line and config file options cannot be both defined and custoemr customization may break.
        # insecure-registry setting was inherited from the past, see b/203231428. Keeping for backward compatibility.
        echo "DOCKER_OPTS=\"--registry-mirror=https://mirror.gcr.io --insecure-registry 10.0.0.0/8\"" > /etc/default/docker

        systemctl daemon-reload
        echo "Docker command line and configuration are updated. Restart docker to pick it up"
        systemctl restart docker
      }

      # Install node problem detector binary.
      function install-node-problem-detector {
        if [[ -n "${NODE_PROBLEM_DETECTOR_VERSION:-}" ]]; then
            local -r npd_version="${NODE_PROBLEM_DETECTOR_VERSION}"
            local -r npd_hash="${NODE_PROBLEM_DETECTOR_TAR_HASH}"
        else
            local -r npd_version="${DEFAULT_NPD_VERSION}"
            case "${HOST_PLATFORM}/${HOST_ARCH}" in
              linux/amd64)
                local -r npd_hash="${DEFAULT_NPD_HASH_AMD64}"
                ;;
              linux/arm64)
                local -r npd_hash="${DEFAULT_NPD_HASH_ARM64}"
                ;;
              # no other architectures are supported currently.
              # Assumption is that this script only runs on linux,
              # see cluster/gce/windows/k8s-node-setup.psm1 for windows
              # https://github.com/kubernetes/node-problem-detector/releases/
              *)
                echo "Unrecognized version and platform/arch combination:"
                echo "$DEFAULT_NPD_VERSION $HOST_PLATFORM/$HOST_ARCH"
                echo "Set NODE_PROBLEM_DETECTOR_VERSION and NODE_PROBLEM_DETECTOR_TAR_HASH to overwrite"
                exit 1
                ;;
            esac
        fi
        local -r npd_tar="node-problem-detector-${npd_version}-${HOST_PLATFORM}_${HOST_ARCH}.tar.gz"

        if is-preloaded "${npd_tar}" "${npd_hash}"; then
          echo "${npd_tar} is preloaded."
          return
        fi

        echo "Downloading ${npd_tar}."
        local -r npd_release_path="${NODE_PROBLEM_DETECTOR_RELEASE_PATH:-${STORAGE_ENDPOINT}/gke-release}"
        download-or-bust "${npd_hash}" "${npd_release_path}/node-problem-detector/${npd_tar}"
        local -r npd_dir="${KUBE_HOME}/node-problem-detector"
        mkdir -p "${npd_dir}"
        tar xzf "${KUBE_HOME}/${npd_tar}" -C "${npd_dir}" --overwrite
        mv "${npd_dir}/bin"/* "${KUBE_BIN}"
        chmod a+x "${KUBE_BIN}/node-problem-detector"
        rmdir "${npd_dir}/bin"
        rm -f "${KUBE_HOME}/${npd_tar}"

        record-preload-info "${npd_tar}" "${npd_hash}"
      }

      # Install node problem detector custom plugins.
      function install-npd-custom-plugins {
        local -r version="${NPD_CUSTOM_PLUGINS_VERSION}"
        case "${HOST_PLATFORM}/${HOST_ARCH}" in
          linux/amd64)
            local -r hash="${NPD_CUSTOM_PLUGINS_TAR_AMD64_HASH}"
            ;;
          linux/arm64)
            local -r hash="${NPD_CUSTOM_PLUGINS_TAR_ARM64_HASH}"
            ;;
          *)
            echo "Unrecognized version and platform/arch combination:"
            echo "$NPD_CUSTOM_PLUGINS_VERSION $HOST_PLATFORM/$HOST_ARCH"
            exit 1
        esac
        local -r tar="npd-custom-plugins-${version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz"

        if is-preloaded "${tar}" "${hash}"; then
          echo "${tar} is preloaded."
          return
        fi

        echo "Downloading ${tar}."
        download-or-bust "${hash}" "${STORAGE_ENDPOINT}/gke-release/npd-custom-plugins/${version}/${tar}"
        local -r dir="${KUBE_HOME}/npd-custom-plugins"
        mkdir -p "${dir}"
        tar xzf "${KUBE_HOME}/${tar}" -C "${dir}" --overwrite
        local -r kube_bin_dir="${KUBE_HOME}/bin"
        cp -r "${dir}/bins"/* "${kube_bin_dir}"
        rm -f "${KUBE_HOME}/${tar}"

        record-preload-info "${tar}" "${hash}"
      }

      function install-cni-binaries {
        local -r cni_version=${CNI_VERSION:-$DEFAULT_CNI_VERSION}
        if [[ -n "${CNI_VERSION:-}" ]]; then
          local -r cni_hash="${CNI_HASH:-}"
        else
          local -r cni_hash_var="DEFAULT_CNI_HASH_${HOST_PLATFORM^^}_${HOST_ARCH^^}"
          local -r cni_hash="${!cni_hash_var}"
        fi

        local -r cni_tar="cni-plugins-${HOST_PLATFORM}-${HOST_ARCH}-${cni_version}.tgz"
        local -r cni_url="${STORAGE_ENDPOINT}/gke-release/cni-plugins/${cni_version}/${cni_tar}"

        if is-preloaded "${cni_tar}" "${cni_hash}"; then
          echo "${cni_tar} is preloaded."
          return
        fi

        echo "Downloading cni binaries"
        download-or-bust "${cni_hash}" "${cni_url}"
        local -r cni_dir="${KUBE_HOME}/cni"
        mkdir -p "${cni_dir}/bin"
        tar xzf "${KUBE_HOME}/${cni_tar}" -C "${cni_dir}/bin" --overwrite
        mv "${cni_dir}/bin"/* "${KUBE_BIN}"
        rmdir "${cni_dir}/bin"
        rm -f "${KUBE_HOME}/${cni_tar}"

        record-preload-info "${cni_tar}" "${cni_hash}"
      }

      # Install crictl binary.
      # Assumptions: HOST_PLATFORM and HOST_ARCH are specified by calling detect_host_info.
      function install-crictl {
        if [[ -n "${CRICTL_VERSION:-}" ]]; then
          local -r crictl_version="${CRICTL_VERSION}"
          local -r crictl_hash="${CRICTL_TAR_HASH}"
        else
          local -r crictl_version="${DEFAULT_CRICTL_VERSION}"
          case "${HOST_PLATFORM}/${HOST_ARCH}" in
            linux/amd64)
              local -r crictl_hash="${DEFAULT_CRICTL_AMD64_SHA512}"
              ;;
            linux/arm64)
              local -r crictl_hash="${DEFAULT_CRICTL_ARM64_SHA512}"
              ;;
            *)
              echo "Unrecognized version and platform/arch combination:"
              echo "$DEFAULT_CRICTL_VERSION $HOST_PLATFORM/$HOST_ARCH"
              echo "Set CRICTL_VERSION and CRICTL_TAR_HASH to overwrite"
              exit 1
          esac
        fi
        local -r crictl="crictl-${crictl_version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz"

        # Create crictl config file.
        cat > /etc/crictl.yaml <<EOF
      runtime-endpoint: ${CONTAINER_RUNTIME_ENDPOINT:-unix:///run/containerd/containerd.sock}
      EOF

        if is-preloaded "${crictl}" "${crictl_hash}"; then
          echo "crictl is preloaded"
          return
        fi

        echo "Downloading crictl"
        local -r crictl_path="${STORAGE_ENDPOINT}/gke-release/cri-tools/${crictl_version}"
        download-or-bust "${crictl_hash}" "${crictl_path}/${crictl}"
        tar xf "${crictl}"
        mv crictl "${KUBE_BIN}/crictl"
        rm -f "${crictl}"

        record-preload-info "${crictl}" "${crictl_hash}"
      }

      function preload-pause-image {
        local -r pause_image="${KUBE_DOCKER_REGISTRY}/${GKE_CONTAINERD_INFRA_CONTAINER}"
        if is-preloaded "pause" "${pause_image}"; then
          echo "pause image is preloaded"
          return
        fi

        # preloading pause image. It will be used in preloader and will be
        # useful for staging builds where access_token is needed to pull the image
        local access_token="";

        if access_token=$(get-credentials); then
          "${KUBE_BIN}/crictl" pull --creds "oauth2accesstoken:${access_token}" "${pause_image}"
        else
          echo "No access token. Pulling without it."
          "${KUBE_BIN}/crictl" pull "${pause_image}"
        fi

        record-preload-info "pause" "${pause_image}"
      }

      function install-exec-auth-plugin {
        if [[ ! "${EXEC_AUTH_PLUGIN_URL:-}" ]]; then
            return
        fi
        local -r plugin_url="${EXEC_AUTH_PLUGIN_URL}"
        local -r plugin_hash="${EXEC_AUTH_PLUGIN_HASH}"

        if is-preloaded "gke-exec-auth-plugin" "${plugin_hash}"; then
          echo "gke-exec-auth-plugin is preloaded"
          return
        fi

        echo "Downloading gke-exec-auth-plugin binary"
        download-or-bust "${plugin_hash}" "${plugin_url}"
        mv "${KUBE_HOME}/gke-exec-auth-plugin" "${KUBE_BIN}/gke-exec-auth-plugin"
        chmod a+x "${KUBE_BIN}/gke-exec-auth-plugin"

        if [[ ! "${EXEC_AUTH_PLUGIN_LICENSE_URL:-}" ]]; then
            return
        fi
        local -r license_url="${EXEC_AUTH_PLUGIN_LICENSE_URL}"
        echo "Downloading gke-exec-auth-plugin license"
        download-or-bust "" "${license_url}"
        mv "${KUBE_HOME}/LICENSE" "${KUBE_BIN}/gke-exec-auth-plugin-license"

        record-preload-info "gke-exec-auth-plugin" "${plugin_hash}"
      }

      function install-kube-manifests {
        # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.
        local dst_dir="${KUBE_HOME}/kube-manifests"
        mkdir -p "${dst_dir}"
        local manifests_tar_urls
        while IFS= read -r url; do
          manifests_tar_urls+=("$url")
        done < <(split-commas "${KUBE_MANIFESTS_TAR_URL}")
        local -r manifests_tar="${manifests_tar_urls[0]##*/}"
        if [ -n "${KUBE_MANIFESTS_TAR_HASH:-}" ]; then
          local -r manifests_tar_hash="${KUBE_MANIFESTS_TAR_HASH}"
        else
          echo "Downloading k8s manifests hash (not found in env)"
          download-or-bust "" "${manifests_tar_urls[@]/.tar.gz/.tar.gz.sha512}"
          local -r manifests_tar_hash=$(cat "${manifests_tar}.sha512")
        fi

        if is-preloaded "${manifests_tar}" "${manifests_tar_hash}"; then
          echo "${manifests_tar} is preloaded."
          return
        fi

        echo "Downloading k8s manifests tar"
        download-or-bust "${manifests_tar_hash}" "${manifests_tar_urls[@]}"
        tar xzf "${KUBE_HOME}/${manifests_tar}" -C "${dst_dir}" --overwrite
        local -r kube_addon_registry="${KUBE_ADDON_REGISTRY:-k8s.gcr.io}"
        if [[ "${kube_addon_registry}" != "k8s.gcr.io" ]]; then
          find "${dst_dir}" \(-name '*.yaml' -or -name '*.yaml.in'\) -print0 | \
            xargs -0 sed -ri "s@(image:\s.*)k8s.gcr.io@\1${kube_addon_registry}@"
          find "${dst_dir}" \(-name '*.manifest' -or -name '*.json'\) -print0 | \
            xargs -0 sed -ri "s@(image\":\s+\")k8s.gcr.io@\1${kube_addon_registry}@"
        fi
        cp "${dst_dir}/kubernetes/gci-trusty/gci-configure-helper.sh" "${KUBE_BIN}/configure-helper.sh"
        cp "${dst_dir}/kubernetes/gci-trusty/configure-kubeapiserver.sh" "${KUBE_BIN}/configure-kubeapiserver.sh"
        if [[ -e "${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh" ]]; then
          cp "${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh" "${KUBE_BIN}/"
        fi
        if [[ -e "${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh" ]]; then
          cp "${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh" "${KUBE_BIN}/"
        fi
        cp "${dst_dir}/kubernetes/gci-trusty/health-monitor.sh" "${KUBE_BIN}/health-monitor.sh"
        cp "${dst_dir}/kubernetes/gci-trusty/networkd-monitor.sh" "${KUBE_BIN}/networkd-monitor.sh"

        rm -f "${KUBE_HOME}/${manifests_tar}"
        rm -f "${KUBE_HOME}/${manifests_tar}.sha512"

        record-preload-info "${manifests_tar}" "${manifests_tar_hash}"
      }

      # Installs hurl to ${KUBE_HOME}/bin/hurl if not already installed.
      function install-hurl {
        cd "${KUBE_HOME}"

        local -r hurl_bin="hurl"
        local -r hurl_gcs_att="instance/attributes/hurl-gcs-url"
        local -r hurl_gcs_url=${HURL_GCS_URL:-$(get-metadata-value "${hurl_gcs_att}")}

        # extracting verison from url, example:
        # $ echo "https://storage.googleapis.com/gke-master-startup/hurl/gke_master_hurl_20230824.00_p0/hurl" | sed -n 's/.*gke_master_hurl_\(.*\)\/hurl/\1/p'
        # 20230824.00_p0
        local -r hurl_version=$(echo "${hurl_gcs_url}" | sed -n 's/.*gke_master_hurl_\(.*\)\/hurl/\1/p')

        if is-preloaded "${hurl_bin}" "${hurl_version}"; then
          echo "install-hurl: hurl already installed"
          return
        fi

        if [[ -z "${hurl_gcs_url}" ]]; then
          # URL not present in GCE Instance Metadata
          echo "install-hurl: Unable to find GCE metadata ${hurl_gcs_att}"
          return
        fi

        # Download hurl binary from a GCS bucket.
        echo "install-hurl: Installing hurl from ${hurl_gcs_url} ... "
        download-or-bust "" "${hurl_gcs_url}"
        if [[ -f "${KUBE_HOME}/${hurl_bin}" ]]; then
          chmod a+x ${KUBE_HOME}/${hurl_bin}
          mv "${KUBE_HOME}/${hurl_bin}" "${KUBE_BIN}/${hurl_bin}"
          echo "install-hurl: hurl installed to ${KUBE_BIN}/${hurl_bin}"
          record-preload-info "${hurl_bin}" "${hurl_version}"
          return
        fi
      }

      # Installs inplace to ${KUBE_HOME}/bin/inplace if not already installed.
      function install-inplace {
        cd "${KUBE_HOME}"
        if [[ -f "${KUBE_HOME}/bin/inplace" ]]; then
          echo "install-inplace: inplace already installed"
          return
        fi
        local -r inplace_gcs_att="instance/attributes/inplace-gcs-url"
        local -r inplace_gcs_url=${INPLACE_GCS_URL:-$(get-metadata-value "${inplace_gcs_att}")}
        if [[ -z "${inplace_gcs_url}" ]]; then
          # URL not present in GCE Instance Metadata
          echo "install-inplace: Unable to find GCE metadata ${inplace_gcs_att}"
          return
        fi
        echo "install-inplace: Installing inplace from ${inplace_gcs_url} ..."
        download-or-bust "" "${inplace_gcs_url}"
        local -r inplace_bin="inplace"
        if [[ -f "${KUBE_HOME}/${inplace_bin}" ]]; then
          mv "${KUBE_HOME}/${inplace_bin}" "${KUBE_BIN}/${inplace_bin}"
          if [[ ! -d "${KUBE_HOME}/${inplace_bin}" ]]; then
            mkdir -p "${KUBE_HOME}/${inplace_bin}"
          fi
          cat > "${KUBE_HOME}/${inplace_bin}/inplace.hash" <<EOF
      ${inplace_gcs_url}
      EOF
          echo "install-inplace: inplace installed to ${KUBE_BIN}/${inplace_bin}"
          return
        fi
      }

      # A function to download in-place component manifests if in-place agent is
      # present.
      function inplace-run-once {
        if [[ -f "${KUBE_HOME}/bin/inplace" ]]; then
          echo "inplace-run-once: using inplace to download inplace component manefists"
          local dst_dir="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty"
          mkdir -p "${dst_dir}/in-place"
          mkdir -p "${dst_dir}/gce-extras/in-place"
          ${KUBE_HOME}/bin/inplace --mode=run-once --in_place_addon_path="${dst_dir}/gce-extras/in-place" --master_pod_path="${dst_dir}/in-place"
        fi
      }

      function install-auger {
        echo "Downloading auger binary"
        if [[ -f "${KUBE_HOME}/bin/auger" ]]; then
          echo "auger is already installed"
          return
        fi
        AUGER_STORE_PATH="${AUGER_STORE_PATH:-${STORAGE_ENDPOINT}/gke-release-staging/auger}"
        AUGER_VERSION="${AUGER_VERSION:-v1.0.0-gke.1}"
        download-or-bust "" "${AUGER_STORE_PATH}/${AUGER_VERSION}/auger.sha1"
        sha1="$(cat auger.sha1)"
        readonly sha1 # Declare readonly separately to avoid masking error values.
        rm -f "auger.sha1"
        download-or-bust "${sha1}" "${AUGER_STORE_PATH}/${AUGER_VERSION}/auger"
        mv "${KUBE_HOME}/auger" "${KUBE_HOME}/bin/auger"
        chmod a+x "${KUBE_HOME}/bin/auger"
        record-preload-info "auger" "${sha1}"
      }

      # Extract etcdctl binary from etcd image.
      function install-etcdctl {
        echo "Installing etcdctl binary"
        if [[ -f "${KUBE_HOME}/bin/etcdctl" ]]; then
          echo "etcdctl is already installed"
          return
        fi
        local -r etcd_image="gcr.io/gke-master-images/etcd:${ETCDCTL_VERSION}"
        container_id="$(docker create "${etcd_image}" sh)"
        readonly containerId
        docker cp "${container_id}:usr/local/bin/etcdctl" "${KUBE_HOME}/bin/etcdctl"
        chmod a+x "${KUBE_HOME}/bin/etcdctl"
        docker rm "${container_id}"
        docker rmi "${etcd_image}"
      }

      function install-gcfsd {
        echo "Downloading Riptide FUSE client"
        if is-preloaded "gcfsd" "${RIPTIDE_FUSE_VERSION}"; then
          echo "gcfsd is preloaded."
          return
        fi

        if [[ "${HOST_ARCH}" == "arm64" ]]; then
          RIPTIDE_FUSE_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}/arm64"
          TAR_SHA="${RIPTIDE_FUSE_ARM64_SHA512}"
          BIN_SHA="${RIPTIDE_FUSE_BIN_ARM64_SHA512}"
        else
          RIPTIDE_FUSE_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}"
          TAR_SHA="${RIPTIDE_FUSE_AMD64_SHA512}"
          BIN_SHA="${RIPTIDE_FUSE_BIN_AMD64_SHA512}"
        fi

        echo "Downloading tarball for gcfsd"
        download-or-bust "${TAR_SHA}" "${RIPTIDE_FUSE_STORE_PATH}/gcfsd.tar.gz"

        download-or-bust "${BIN_SHA}" "${RIPTIDE_FUSE_STORE_PATH}/gcfsd"
        mv "${KUBE_HOME}/gcfsd" "${KUBE_HOME}/bin/gcfsd"
        chmod a+x "${KUBE_HOME}/bin/gcfsd"
        record-preload-info "gcfsd" "${RIPTIDE_FUSE_VERSION}"
      }

      function install-riptide-snapshotter {
        echo "Downloading Riptide snapshotter"
        if is-preloaded "containerd-gcfs-grpc" "${RIPTIDE_SNAPSHOTTER_VERSION}"; then
          echo "containerd-gcfs-grpc is preloaded."
          return
        fi
        RIPTIDE_SNAPSHOTTER_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfs-snapshotter/${RIPTIDE_SNAPSHOTTER_VERSION}"

        echo "Downloading tarball for riptide-snapshotter"
        download-or-bust "${RIPTIDE_SNAPSHOTTER_SHA512}" "${RIPTIDE_SNAPSHOTTER_STORE_PATH}/containerd-gcfs-grpc.tar.gz"

        if [[ "${HOST_ARCH}" == "arm64" ]]; then
          RIPTIDE_SNAPSHOTTER_BINARY="containerd-gcfs-grpc-arm64"
          RIPTIDE_SNAPSHOTTER_BIN_SHA512="${RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512}"
        else
          RIPTIDE_SNAPSHOTTER_BINARY="containerd-gcfs-grpc"
          RIPTIDE_SNAPSHOTTER_BIN_SHA512="${RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512}"
        fi

        download-or-bust "${RIPTIDE_SNAPSHOTTER_BIN_SHA512}" "${RIPTIDE_SNAPSHOTTER_STORE_PATH}/${RIPTIDE_SNAPSHOTTER_BINARY}"
        mv "${KUBE_HOME}/${RIPTIDE_SNAPSHOTTER_BINARY}" "${KUBE_HOME}/bin/containerd-gcfs-grpc"
        chmod a+x "${KUBE_HOME}/bin/containerd-gcfs-grpc"
        record-preload-info "containerd-gcfs-grpc" "${RIPTIDE_SNAPSHOTTER_VERSION}"
      }

      # Install Riptide FUSE client and Riptide snapshotter
      function install-riptide {
        install-gcfsd
        install-riptide-snapshotter
      }

      function install-auth-provider-gcp {
        case "${HOST_ARCH}" in
          amd64)
            local -r auth_provider_gcp_hash="${AUTH_PROVIDER_GCP_HASH_LINUX_AMD64}"
            ;;
          arm64)
            local -r auth_provider_gcp_hash="${AUTH_PROVIDER_GCP_HASH_LINUX_ARM64}"
            ;;
          *)
            echo "Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}"
            exit 1
        esac

        if is-preloaded "auth-provider-gcp" "${auth_provider_gcp_hash}"; then
          echo "auth-provider-gcp is preloaded."
          return
        fi

        local -r auth_provider_storage_url="${STORAGE_ENDPOINT}/gke-release/auth-provider-gcp/${AUTH_PROVIDER_GCP_VERSION}/${HOST_PLATFORM}_${HOST_ARCH}/auth-provider-gcp"
        echo "Downloading auth-provider-gcp ${auth_provider_storage_url}" .
        download-or-bust "${auth_provider_gcp_hash}" "${auth_provider_storage_url}"

        # Keep in sync with --image-credential-provider-bin-dir in cloud/kubernetes/distro/legacy/kube_env.go
        mv "${KUBE_HOME}/auth-provider-gcp" "${KUBE_BIN}"
        chmod a+x "${KUBE_BIN}/auth-provider-gcp"

        record-preload-info "auth-provider-gcp" "${auth_provider_gcp_hash}"
      }

      function download-gvisor-installer {
        local -r installer_image_hash=$1
        local -r installer_image="${KUBE_DOCKER_REGISTRY}/gke-gvisor-installer@sha256:${installer_image_hash}"
        if access_token=$(get-credentials); then
          "${KUBE_BIN}/crictl" pull --creds "oauth2accesstoken:${access_token}" "${installer_image}"
        else
          "${KUBE_BIN}/crictl" pull "${installer_image}"
        fi
      }

      function configure-cgroup-mode {
        if which cgroup_helper > /dev/null 2>&1; then
          if [[ "${CGROUP_MODE:-}" == "v1" ]] && cgroup_helper show | grep -q 'unified'; then
            cgroup_helper set hybrid
            echo "set cgroup config to hybrid, now rebooting..."
            reboot
          elif [[ "${CGROUP_MODE:-}" == "v2" ]] && cgroup_helper show | grep -q 'hybrid'; then
            cgroup_helper set unified
            echo "set cgroup config to unified, now rebooting..."
            reboot
          fi
        fi
      }

      # To improve the shieded VM reliability b/327650100
      function check-tpm-file {
        if [[ -z "${TPM_BOOTSTRAP_KEY:-}" ]]; then
          echo "TPM_BOOTSTRAP_KEY is empty, thus vTPM is disabled, skip tpm file check"
          return 0
        else
          echo "TPM_BOOTSTRAP_KEY is not empty, thus vTPM is enabled, checking tpm file"
          if [[ -e "/dev/tpm0" ]]; then
            echo "/dev/tpm0 exists."
            return 0
          else
            echo "/dev/tpm0 doesn't exist."
            return 1
          fi
        fi
      }

      function detect-reboot-needed {
        # Exit if it is on the master
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          return
        fi

        if [[ "${ENABLE_BEST_EFFORT_NODE_REBOOT:-}" == "true" ]]; then
          if check-tpm-file; then
            echo "TPM is present; continuing bootstrap..."
            return
          fi

          echo "TPM file check doesn't pass!"
          if ! REBOOT_HISTORY=$(journalctl --list-boots --quiet | wc -l); then
            echo "skip reboot attempt due to the journalctl error"
            return
          fi
          if [[ $(($REBOOT_HISTORY)) -gt ${MAX_BOOT_COUNT} ]]; then
            echo "best effort reboot attempt ${REBOOT_HISTORY} exceed ${MAX_BOOT_COUNT}! stop rebooting!"
          else
            echo "best effort reboot attempt ${REBOOT_HISTORY}! rebooting..."
            reboot
          fi
        fi
      }

      # A helper function for loading a docker image. It keeps trying up to 5 times.
      #
      # $1: Full path of the docker image
      function try-load-docker-image {
        local -r img=$1
        echo "Try to load docker image file ${img}"
        # Temporarily turn off errexit, because we don't want to exit on first failure.
        set +e
        local -r max_attempts=5
        local -i attempt_num=1

        if [[ "${CONTAINER_RUNTIME_NAME:-}" == "containerd" || "${CONTAINERD_TEST:-}"  == "containerd" ]]; then
          load_image_command=${LOAD_IMAGE_COMMAND:-ctr -n=k8s.io images import}
        else
          load_image_command="${LOAD_IMAGE_COMMAND:-}"
        fi

        # Deliberately word split load_image_command
        # shellcheck disable=SC2086
        until timeout 30 ${load_image_command} "${img}"; do
          if [[ "${attempt_num}" == "${max_attempts}" ]]; then
            echo "Fail to load docker image file ${img} using ${load_image_command} after ${max_attempts} retries. Exit!!"
            exit 1
          else
            attempt_num=$((attempt_num+1))
            sleep 5
          fi
        done
        # Re-enable errexit.
        set -e
      }

      # Loads kube-system docker images. It is better to do it before starting kubelet,
      # as kubelet will restart docker daemon, which may interfere with loading images.
      function load-docker-images {
        echo "Start loading kube-system docker images"
        local -r img_dir="${KUBE_HOME}/kube-docker-files"
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          try-load-docker-image "${img_dir}/kube-apiserver.tar"
          try-load-docker-image "${img_dir}/kube-controller-manager.tar"
          try-load-docker-image "${img_dir}/kube-scheduler.tar"
        else
          try-load-docker-image "${img_dir}/kube-proxy.tar"
        fi
      }

      # A helper function for retagging a docker image.
      # $1: Image prefix
      # $2: Image tag
      # $3: Destination tag
      function retag-docker-image {
        local -r img_prefix=$1
        local -r img_tag=$2
        local -r dest_tag=$3
        if [[ "${img_tag}" == "${dest_tag}" ]]; then
          echo "Source image tag: ${img_tag} and destination image tag: ${dest_tag} are the same. Skipping retagging."
        else
          echo "Retagging all images with prefix: ${img_prefix} and tag: ${img_tag} with new tag: ${dest_tag}"
          local src_img=""
          for src_img in $(ctr -n=k8s.io images list -q | grep "/${img_prefix}" | grep ":${img_tag}$"); do
            dest_img=${src_img/:${img_tag}/:${dest_tag}}
            cmd="ctr -n=k8s.io image tag ${src_img} ${dest_img} --force"
            echo "Retag command: ${cmd}"
            ${cmd}
          done
        fi
      }


      # Retags kube-system docker images with passed in kube-apiserver/kubelet versions.
      function retag-docker-images {
        echo "Start retagging kube-system docker images"
        local src_tag=""
        local dest_tag=""
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          if [[ -n "${KUBE_APISERVER_VERSION:-}" ]]; then
            src_tag=$(cat /home/kubernetes/kube-docker-files/kube-apiserver.docker_tag)
            # Docker tags cannot contain '+', make CI versions a valid docker tag.
            dest_tag=${KUBE_APISERVER_VERSION/+/_}
            retag-docker-image "kube-apiserver" "${src_tag}" "${dest_tag}"
            retag-docker-image "kube-controller-manager" "${src_tag}" "${dest_tag}"
            retag-docker-image "kube-scheduler" "${src_tag}" "${dest_tag}"
          fi
        else
          if [[ -n "${KUBELET_VERSION:-}" ]]; then
            src_tag=$(cat /home/kubernetes/kube-docker-files/kube-proxy.docker_tag)
            # Docker tags cannot contain '+', make CI versions a valid docker tag.
            dest_tag=${KUBELET_VERSION/+/_}
            retag-docker-image "kube-proxy" "${src_tag}" "${dest_tag}"
          fi
        fi
      }


      function ensure-container-runtime {
        if [[ "${CONTAINER_RUNTIME}" == "docker" ]]; then
          echo "Dockershim is not supported. Container runtime must be set to containerd"
          exit 2
        fi
      }

      # Downloads kubernetes binaries and kube-system manifest tarball, unpacks them,
      # and places them into suitable directories. Files are placed in /home/kubernetes.
      function install-kube-binary-config {
        cd "${KUBE_HOME}"
        local server_binary_tar_urls
        while IFS= read -r url; do
          server_binary_tar_urls+=("$url")
        done < <(split-commas "${SERVER_BINARY_TAR_URL}")
        local -r server_binary_tar="${server_binary_tar_urls[0]##*/}"
        if [[ -n "${SERVER_BINARY_TAR_HASH:-}" ]]; then
          local -r server_binary_tar_hash="${SERVER_BINARY_TAR_HASH}"
        else
          echo "Downloading binary release sha512 (not found in env)"
          download-or-bust "" "${server_binary_tar_urls[@]/.tar.gz/.tar.gz.sha512}"
          local -r server_binary_tar_hash=$(cat "${server_binary_tar}.sha512")
        fi

        if is-preloaded "${server_binary_tar}" "${server_binary_tar_hash}"; then
          echo "${server_binary_tar} is preloaded."
        else
          echo "Downloading binary release tar"
          download-or-bust "${server_binary_tar_hash}" "${server_binary_tar_urls[@]}"
          tar xzf "${KUBE_HOME}/${server_binary_tar}" -C "${KUBE_HOME}" --overwrite
          # Copy docker_tag and image files to ${KUBE_HOME}/kube-docker-files.
          local -r src_dir="${KUBE_HOME}/kubernetes/server/bin"
          local dst_dir="${KUBE_HOME}/kube-docker-files"
          mkdir -p "${dst_dir}"
          cp "${src_dir}/"*.docker_tag "${dst_dir}"
          if [[ "${KUBERNETES_MASTER:-}" == "false" ]]; then
            cp "${src_dir}/kube-proxy.tar" "${dst_dir}"
          else
            cp "${src_dir}/kube-apiserver.tar" "${dst_dir}"
            cp "${src_dir}/kube-controller-manager.tar" "${dst_dir}"
            cp "${src_dir}/kube-scheduler.tar" "${dst_dir}"
            cp -r "${KUBE_HOME}/kubernetes/addons" "${dst_dir}"
          fi
          load-docker-images
          mv "${src_dir}/kubelet" "${KUBE_BIN}"
          mv "${src_dir}/kubectl" "${KUBE_BIN}"

          # Some older images have LICENSES baked-in as a file. Presumably they will
          # have the directory baked-in eventually.
          rm -rf "${KUBE_HOME}"/LICENSES
          mv "${KUBE_HOME}/kubernetes/LICENSES" "${KUBE_HOME}"
          mv "${KUBE_HOME}/kubernetes/kubernetes-src.tar.gz" "${KUBE_HOME}"

          record-preload-info "${server_binary_tar}" "${server_binary_tar_hash}"
        fi

        retag-docker-images

        if [[ "${NETWORK_PROVIDER:-}" == "kubenet" ]] || \
           [[ "${NETWORK_PROVIDER:-}" == "cni" ]]; then
          install-cni-binaries
        fi

        # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.
        install-kube-manifests
        chmod -R 755 "${KUBE_BIN}"

        # Install gci mounter related artifacts to allow mounting storage volumes in GCI
        install-gci-mounter-tools

        # Remount the Flexvolume directory with the "exec" option, if needed.
        if [[ "${REMOUNT_VOLUME_PLUGIN_DIR:-}" == "true" && -n "${VOLUME_PLUGIN_DIR:-}" ]]; then
          remount-flexvolume-directory "${VOLUME_PLUGIN_DIR}"
        fi

        # Install crictl on each node.
        install-crictl

        # Preload pause image
        preload-pause-image

        # Copy health check binaries to a tmpfs mount to reduce block IO usage.
        setup-shm-healthcheck-binaries

        # TODO(awly): include the binary and license in the OS image.
        install-exec-auth-plugin

        if [[ "${KUBERNETES_MASTER:-}" == "false" ]] && \
           [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "standalone" ]]; then
          install-node-problem-detector
          install-npd-custom-plugins
        fi

        # Clean up.
        rm -rf "${KUBE_HOME}/kubernetes"
        rm -f "${KUBE_HOME}/${server_binary_tar}"
        rm -f "${KUBE_HOME}/${server_binary_tar}.sha512"
      }

      function setup-shm-healthcheck-binaries() {
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          return
        fi
        if [[ "${ENABLE_SHM_HEALTHCHECK_BINARIES:-}" != "true" ]];then
          return
        fi

        local -r shm_dir="${HEALTHCHECK_SHM_DIR:-/dev/kube_shm}"
        local -r shm_bin_dir="${shm_dir}/bin"

        mkdir -p "$shm_dir"
        mount -t tmpfs -o exec none "$shm_dir"
        mkdir "${shm_bin_dir}"

        cp -f "${KUBE_BIN}/crictl" "${shm_bin_dir}/crictl"
        cp -f "$(which curl)" "${shm_bin_dir}/curl"
      }

      function configure-pga-if-needed() {
        echo "Detecting connectivity to ${STORAGE_ENDPOINT}..."
        local status=0
        curl --ipv4 -L --connect-timeout 10 --retry 3  --retry-connrefused ${STORAGE_ENDPOINT} || status="$?"
        # connection is refused(7) or timeout(28).
        if [[ "${status}" == "7" || "${status}" == "28" ]]; then
          status=0
          local pga_ip
          pga_ip=`curl ${PGA_ENDPOINT} -w '%{remote_ip}' --connect-timeout 10 -s -o /dev/null` || status="$?"
          if [[ "${status}" == "0" ]]; then
            echo "Configure /etc/hosts to use private google access"
            echo "$pga_ip ${STORAGE_ENDPOINT#https://}" >> /etc/hosts
            echo "$pga_ip ${KUBE_DOCKER_REGISTRY}" >> /etc/hosts
          fi
        fi
      }

      # This function detects the platform/arch of the machine where the script runs,
      # and sets the HOST_PLATFORM and HOST_ARCH environment variables accordingly.
      # Callers can specify HOST_PLATFORM_OVERRIDE and HOST_ARCH_OVERRIDE to skip the detection.
      # This function is adapted from the detect_client_info function in cluster/get-kube-binaries.sh
      # and kube::util::host_os, kube::util::host_arch functions in hack/lib/util.sh
      # This function should be synced with detect_host_info in ./configure-helper.sh
      function detect_host_info() {
        HOST_PLATFORM=${HOST_PLATFORM_OVERRIDE:-"$(uname -s)"}
        case "${HOST_PLATFORM}" in
          Linux|linux)
            HOST_PLATFORM="linux"
            ;;
          *)
            echo "Unknown, unsupported platform: ${HOST_PLATFORM}." >&2
            echo "Supported platform(s): linux." >&2
            echo "Bailing out." >&2
            exit 2
        esac

        HOST_ARCH=${HOST_ARCH_OVERRIDE:-"$(uname -m)"}
        case "${HOST_ARCH}" in
          x86_64*|i?86_64*|amd64*)
            HOST_ARCH="amd64"
            ;;
          aHOST_arch64*|aarch64*|arm64*)
            HOST_ARCH="arm64"
            ;;
          *)
            echo "Unknown, unsupported architecture (${HOST_ARCH})." >&2
            echo "Supported architecture(s): amd64 and arm64." >&2
            echo "Bailing out." >&2
            exit 2
            ;;
        esac
      }

      # Retries a command forever with a delay between retries.
      # Args:
      #  $1    : delay between retries, in seconds.
      #  $2... : the command to run.
      function retry-forever {
        local -r delay="$1"
        shift 1

        until "$@"; do
          echo "== $* failed, retrying after ${delay}s"
          sleep "${delay}"
        done
      }

      # Initializes variables used by the log-* functions.
      #
      # get-metadata-value must be defined before calling this function.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-init {
        # Used by log-* functions.
        LOG_CLUSTER_ID=${LOG_CLUSTER_ID:-$(get-metadata-value 'instance/attributes/cluster-uid' 'get-metadata-value-error')}
        LOG_INSTANCE_NAME=$(hostname || echo 'hostname-error')
        LOG_BOOT_ID=$(journalctl --list-boots | grep -E '^ *0' | awk '{print $2}' || echo 'journalctl-error')
        declare -Ag LOG_START_TIMES
        declare -ag LOG_TRAP_STACK

        LOG_STATUS_STARTED='STARTED'
        LOG_STATUS_COMPLETED='COMPLETED'
        LOG_STATUS_ERROR='ERROR'
      }

      # Sets an EXIT trap.
      # Args:
      #   $1:... : the trap command.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-trap-push {
        local t="${*:1}"
        LOG_TRAP_STACK+=("${t}")
        # shellcheck disable=2064
        trap "${t}" EXIT
      }

      # Removes and restores an EXIT trap.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-trap-pop {
        # Remove current trap.
        unset 'LOG_TRAP_STACK[-1]'

        # Restore previous trap.
        if [ ${#LOG_TRAP_STACK[@]} -ne 0 ]; then
          local t="${LOG_TRAP_STACK[-1]}"
          # shellcheck disable=2064
          trap "${t}" EXIT
        else
          # If no traps in stack, clear.
          trap EXIT
        fi
      }

      # Logs the end of a bootstrap step that errored.
      # Args:
      #  $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-error {
        local bootstep="$1"

        log-proto "${bootstep}" "${LOG_STATUS_ERROR}" "encountered non-zero exit code"
      }

      # Wraps a command with bootstrap logging.
      # Args:
      #   $1    : bootstrap step name.
      #   $2... : the command to run.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-wrap {
        local bootstep="$1"
        local command="${*:2}"

        log-trap-push "log-error ${bootstep}"
        log-proto "${bootstep}" "${LOG_STATUS_STARTED}"
        $command
        log-proto "${bootstep}" "${LOG_STATUS_COMPLETED}"
        log-trap-pop
      }

      # Logs a bootstrap step start. Prefer log-wrap.
      # Args:
      #   $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-start {
        local bootstep="$1"

        log-trap-push "log-error ${bootstep}"
        log-proto "${bootstep}" "${LOG_STATUS_STARTED}"
      }

      # Logs a bootstrap step end. Prefer log-wrap.
      # Args:
      #   $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-end {
        local bootstep="$1"

        log-proto "${bootstep}" "${LOG_STATUS_COMPLETED}"
        log-trap-pop
      }

      # Writes a log proto to stdout.
      # Args:
      #   $1: bootstrap step name.
      #   $2: status. Either 'STARTED', 'COMPLETED', or 'ERROR'.
      #   $3: optional status reason.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-proto {
        local bootstep="$1"
        local status="$2"
        local status_reason="${3:-}"

        # Get current time.
        local current_time
        current_time="$(date --utc '+%s.%N')"
        # ...formatted as UTC RFC 3339.
        local timestamp
        timestamp="$(date --utc --date="@${current_time}" '+%FT%T.%NZ')"

        # Calculate latency.
        local latency='null'
        if [ "${status}" == "${LOG_STATUS_STARTED}" ]; then
          LOG_START_TIMES["${bootstep}"]="${current_time}"
        else
          local start_time="${LOG_START_TIMES["${bootstep}"]}"
          unset 'LOG_START_TIMES['"${bootstep}"']'

          # Bash cannot do non-integer math, shell out to awk.
          latency="$(echo "${current_time} ${start_time}" | awk '{print $1 - $2}')s"

          # The default latency is null which cannot be wrapped as a string so we must
          # do it here instead of the printf.
          latency="\"${latency}\""
        fi

        printf '[cloud.kubernetes.monitoring.proto.SerialportLog] {"cluster_hash":"%s","vm_instance_name":"%s","boot_id":"%s","timestamp":"%s","bootstrap_status":{"step_name":"%s","status":"%s","status_reason":"%s","latency":%s}}\n' \
        "${LOG_CLUSTER_ID}" "${LOG_INSTANCE_NAME}" "${LOG_BOOT_ID}" "${timestamp}" "${bootstep}" "${status}" "${status_reason}" "${latency}"
      }

      # Prelaod components for both - preloader and runtime
      # Variables needed for this function to work will be set by the preloader
      function preload {
        cd "${KUBE_HOME}"
        if [[ "${ENABLE_AUTH_PROVIDER_GCP:-""}" == "true" ]]; then
          log-wrap 'InstallExternalCredentialProvider' install-auth-provider-gcp
        fi

        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          log-wrap 'InstallHurl' install-hurl
        fi

        if [[ "${KUBERNETES_MASTER:-}" != "true" && -n "${GVISOR_INSTALLER_IMAGE_HASH:-}" ]]; then
          log-wrap 'DownloadGvisorInstaller' download-gvisor-installer "${GVISOR_INSTALLER_IMAGE_HASH}"
        fi
      }

      ######### Main Function ##########
      log-init
      detect_host_info

      # Preloader will source this script, and skip the main function. The preloader
      # will choose what to preload by calling install-X functions directly.
      # When configure.sh is sourced by the preload script, $0 and $BASH_SOURCE are
      # different. $BASH_SOURCE still contains the path of configure.sh, while $0 is
      # the path of the preload script.
      if [[ "$0" != "$BASH_SOURCE" && "${IS_PRELOADER:-"false"}" == "true" ]]; then
        # preload common components
        preload
        echo "Running in preloader instead of VM bootsrapping. Skipping installation steps as preloader script will source configure.sh and call all non-common functions."
        return
      fi

      log-start 'ConfigureMain'
      echo "Start to install kubernetes files"

      # if install fails, message-of-the-day (motd) will warn at login shell
      log-wrap 'SetBrokenMotd' set-broken-motd

      KUBE_HOME="/home/kubernetes"
      KUBE_BIN="${KUBE_HOME}/bin"

      if [[ "$(is-master)" == "true" ]]; then
        log-wrap 'InstallHurl' install-hurl
        log-wrap 'InstallInplace' install-inplace
      fi

      # download and source kube-env
      log-wrap 'DownloadKubeEnv' download-kube-env
      log-wrap 'SourceKubeEnv' source "${KUBE_HOME}/kube-env"

      if [[ "${CONFIGURE_PGA}" == "true" ]]; then
        configure-pga-if-needed
      fi

      log-wrap 'ConfigureCgroupMode' configure-cgroup-mode

      log-wrap 'BestEffortRebootDetection' detect-reboot-needed

      log-wrap 'DownloadKubeletConfig' download-kubelet-config "${KUBE_HOME}/kubelet-config.yaml"

      if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
        log-wrap 'DownloadKubeMasterCerts' download-kube-master-certs-hurl
      fi

      if docker-installed; then
        # We still need to configure docker so it wouldn't reserver the 172.17.0/16 subnet
        # And if somebody will start docker to build or pull something, logging will also be set up
        log-wrap 'AssembleDockerFlags' assemble-docker-flags
      fi

      # preload common components
      preload

      # ensure chosen container runtime is present
      log-wrap 'EnsureContainerRuntime' ensure-container-runtime

      # binaries and kube-system manifests
      log-wrap 'InstallKubeBinaryConfig' install-kube-binary-config

      # install Riptide components on non-Ubuntu nodes
      if ! is-ubuntu && [[ "${KUBERNETES_MASTER:-}" != "true" ]]; then
        log-wrap 'InstallRiptide' install-riptide
      fi

      # download inplace component manifests
      if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
        log-wrap 'InplaceRunOnce' retry-forever 30 inplace-run-once
      fi

      echo "Done for installing kubernetes files"
      log-end 'ConfigureMain'
  - key: disable-legacy-endpoints
    value: 'true'
  - key: user-data
    value: |
      #cloud-config

      users:
        - name: kube-bootstrap-logs-forwarder
          gecos: User the kube-bootstrap-logs-forwarder.service runs as.
          system: true

      write_files:
        - path: /etc/systemd/system/kube-bootstrap-logs-forwarder.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Forwards Kubernetes bootstrap logs to serial port.
            Before=kube-node-installation.service

            [Service]
            User=kube-bootstrap-logs-forwarder
            Group=systemd-journal
            SupplementaryGroups=serial
            ExecStart=journalctl --no-tail --no-pager --follow --utc --output short-iso --unit kube-node-installation --unit kube-node-configuration --unit kubelet
            StandardOutput=tty
            TTYPath=/dev/ttyS2

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-node-installation.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Download and install k8s binaries and configurations
            After=network-online.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/bin/mkdir -p /home/kubernetes/bin
            ExecStartPre=/bin/mount --bind /home/kubernetes/bin /home/kubernetes/bin
            ExecStartPre=/bin/mount -o remount,exec /home/kubernetes/bin
            ExecStartPre=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H "X-Google-Metadata-Request: True" -o /home/kubernetes/bin/configure.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/configure-sh
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure.sh
            ExecStart=/home/kubernetes/bin/configure.sh

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-node-configuration.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Configure kubernetes node
            After=kube-node-installation.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure-helper.sh
            ExecStart=/home/kubernetes/bin/configure-helper.sh
            ExecStartPost=systemctl stop kube-bootstrap-logs-forwarder.service

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-container-runtime-monitor.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes health monitoring for container runtime
            After=kube-node-configuration.service

            [Service]
            Restart=always
            RestartSec=10
            RemainAfterExit=yes
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh
            ExecStart=/home/kubernetes/bin/health-monitor.sh container-runtime

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kubelet-monitor.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes health monitoring for kubelet
            After=kube-node-configuration.service

            [Service]
            Restart=always
            RestartSec=10
            RemainAfterExit=yes
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh
            ExecStart=/home/kubernetes/bin/health-monitor.sh kubelet

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-logrotate.timer
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Hourly kube-logrotate invocation

            [Timer]
            OnCalendar=hourly

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-logrotate.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes log rotation
            After=kube-node-configuration.service

            [Service]
            Type=oneshot
            # The relative path is being used as the path is different between image types - for example between Ubuntu and COS. See ExecSearchPath for allowed paths.
            ExecSearchPath=/usr/bin:/usr/sbin
            ExecStart=logrotate /etc/logrotate.conf

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kubernetes.target
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes

            [Install]
            WantedBy=multi-user.target

        - path: /etc/modprobe.d/sunrpc.conf
          permissions: '0644'
          owner: root
          # The GKE metadata server uses ports 987-989, so the sunrpc range should be restricted to be below.
          content: |
            options sunrpc max_resvport=986

      runcmd:
       - systemctl daemon-reload
       - systemctl enable kube-bootstrap-logs-forwarder.service
       - systemctl enable kube-node-installation.service
       - systemctl enable kube-node-configuration.service
       - systemctl enable kube-container-runtime-monitor.service
       - systemctl enable kubelet-monitor.service
       - systemctl enable kube-logrotate.timer
       - systemctl enable kube-logrotate.service
       - systemctl enable kubernetes.target
       - systemctl start kubernetes.target
  - key: kube-env
    value: |
      ALLOCATE_NODE_CIDRS: "true"
      API_SERVER_TEST_LOG_LEVEL: --v=3
      AUTOSCALER_ENV_VARS: kube_reserved=cpu=110m,memory=9012Mi,ephemeral-storage=41Gi;node_labels=cloud.google.com/gke-accelerator=nvidia-tesla-v100,cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=32,cloud.google.com/gke-gpu-driver-version=latest,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=n1,cloud.google.com/private-node=false;arch=amd64;os=linux;os_distribution=cos;evictionHard=memory.available=100Mi,nodefs.available=10%,nodefs.inodesFree=5%,pid.available=10%
      CA_CERT: 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
      CLOUD_MONARCH_ENDPOINT: https://monitoring.googleapis.com/
      CLUSTER_IP_RANGE: 10.40.0.0/14
      CLUSTER_NAME: gpu-cluster-16
      CONFIGURE_PGA: "true"
      CONTAINER_RUNTIME: containerd
      CONTAINER_RUNTIME_ENDPOINT: unix:///run/containerd/containerd.sock
      CONTAINER_RUNTIME_NAME: containerd
      CONTAINERD_DEPRECATION_CHECKER: "true"
      CONTAINERD_MAX_CONTAINER_LOG_LINE: "262144"
      CREATE_BOOTSTRAP_KUBECONFIG: "false"
      DETECT_LOCAL_MODE: NodeCIDR
      DETECT_MTU: "true"
      DNS_DOMAIN: cluster.local
      DNS_SERVER_IP: 34.118.224.10
      DOCKER_REGISTRY_MIRROR_URL: https://mirror.gcr.io
      ELASTICSEARCH_LOGGING_REPLICAS: "1"
      ENABLE_AUTH_PROVIDER_GCP: "true"
      ENABLE_CLUSTER_DNS: "true"
      ENABLE_CLUSTER_LOGGING: "false"
      ENABLE_CLUSTER_MONITORING: none
      ENABLE_CLUSTER_REGISTRY: "false"
      ENABLE_CLUSTER_UI: "true"
      ENABLE_CONNTRACK_EXEMPT_HC: "true"
      ENABLE_CONTAINERD_METRICS: "true"
      ENABLE_CONTAINERD_NRI: "true"
      ENABLE_L7_LOADBALANCING: glbc
      ENABLE_LATEST_NPD: "true"
      ENABLE_METADATA_AGENT: ""
      ENABLE_METRICS_SERVER: "true"
      ENABLE_NODE_BFQ_IO_SCHEDULER: "true"
      ENABLE_NODE_LOGGING: "false"
      ENABLE_NODE_PROBLEM_DETECTOR: standalone
      ENABLE_NODE_REGISTRATION_CHECKER: "true"
      ENABLE_NODELOCAL_DNS: "false"
      ENABLE_SHM_HEALTHCHECK_BINARIES: "true"
      ENABLE_SYSCTL_TUNING: "true"
      ENV_TIMESTAMP: "2024-08-30T15:06:41+00:00"
      EXEC_AUTH_PLUGIN_HASH: 1e3e03770805fd4f670f51f4f138f2f9af0ffe16c531d6512bcaec02aab98cec7977da5a84ffbc6509e02989db613c1535f0e14af871078b9520a9f2325374b4
      EXEC_AUTH_PLUGIN_LICENSE_URL: https://storage.googleapis.com/gke-prod-binaries/gke-exec-auth-plugin/8e4840462445ac0edd615a1e6175f44efda4908a/LICENSE
      EXEC_AUTH_PLUGIN_SHA1: 96035ca5744c1d4bd797974ac8f3e1ccbf105ea7
      EXEC_AUTH_PLUGIN_URL: https://storage.googleapis.com/gke-prod-binaries/gke-exec-auth-plugin/8e4840462445ac0edd615a1e6175f44efda4908a/linux_amd64/gke-exec-auth-plugin
      EXTRA_DOCKER_OPTS: --insecure-registry 10.0.0.0/8
      EXTRA_POD_SYSCTLS: net.ipv6.conf.all.disable_ipv6=1,net.ipv6.conf.default.disable_ipv6=1
      FEATURE_GATES: InTreePluginAWSUnregister=true,InTreePluginAzureDiskUnregister=true,InTreePluginvSphereUnregister=true,DisableKubeletCloudCredentialProviders=true,RotateKubeletServerCertificate=true,GracefulNodeShutdown=true,ExecProbeTimeout=false
      FLUENTD_CONTAINER_RUNTIME_SERVICE: containerd
      GVISOR_METRIC_SERVER: 127.0.0.1:9115
      HEAPSTER_USE_NEW_STACKDRIVER_RESOURCES: "true"
      HEAPSTER_USE_OLD_STACKDRIVER_RESOURCES: "false"
      HPA_USE_REST_CLIENTS: "true"
      INSTANCE_PREFIX: gke-gpu-cluster-16-1abef528
      KUBE_ADDON_REGISTRY: k8s.gcr.io
      KUBE_CLUSTER_DNS: 34.118.224.10
      KUBE_DOCKER_REGISTRY: gke.gcr.io
      KUBE_MANIFESTS_TAR_HASH: 8af46c3b756a8c16d5d64305fb86ccf05b670efddd6fd16ebce0ad2d3f4f583f8b310f80d97158046a5230b735ef4437a09b96b17dccc8caeca0559d1d60e0a1
      KUBE_MANIFESTS_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.29.7-gke.1104000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.29.7-gke.1104000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.29.7-gke.1104000/kubernetes-manifests.tar.gz
      KUBE_PROXY_TOKEN: y4D9h358Z1FgiD0JHvGzY9yRfTfBOZXu--cIKxW6bpg=
      KUBELET_ARGS: --v=2 --cloud-provider=external --experimental-mounter-path=/home/kubernetes/containerized_mounter/mounter
        --cert-dir=/var/lib/kubelet/pki/ --kubeconfig=/var/lib/kubelet/kubeconfig --image-credential-provider-config=/etc/srv/kubernetes/cri_auth_config.yaml
        --image-credential-provider-bin-dir=/home/kubernetes/bin --max-pods=110 --volume-plugin-dir=/home/kubernetes/flexvolume
        --node-status-max-images=25 --container-runtime-endpoint=unix:///run/containerd/containerd.sock
        --runtime-cgroups=/system.slice/containerd.service --registry-qps=10 --registry-burst=20
      KUBELET_VERSION: v1.29.7-gke.1104000
      KUBERNETES_MASTER: "false"
      KUBERNETES_MASTER_NAME: 10.128.0.68
      LOAD_IMAGE_COMMAND: ctr -n=k8s.io images import
      LOGGING_DESTINATION: ""
      LOGGING_STACKDRIVER_RESOURCE_TYPES: ""
      MONITORING_FLAG_SET: "true"
      NETWORK_PROVIDER: kubenet
      NODE_BFQ_IO_SCHEDULER_IO_WEIGHT: "1200"
      NODE_LOCAL_SSDS_EXT: ""
      NON_MASQUERADE_CIDR: 0.0.0.0/0
      REMOUNT_VOLUME_PLUGIN_DIR: "true"
      REQUIRE_METADATA_KUBELET_CONFIG_FILE: "true"
      SALT_TAR_HASH: ""
      SALT_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.29.7-gke.1104000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.29.7-gke.1104000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.29.7-gke.1104000/kubernetes-salt.tar.gz
      SERVER_BINARY_TAR_HASH: 74ab81088cff0386b0e51431241d160eece68efd244f3bb8a4e5d98900209192ca0b7590cadb9343025a2e76bdac72c1015807c72de47cb90a24d88a171953a0
      SERVER_BINARY_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.29.7-gke.1104000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.29.7-gke.1104000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.29.7-gke.1104000/kubernetes-server-linux-amd64.tar.gz
      SERVICE_CLUSTER_IP_RANGE: 34.118.224.0/20
      STACKDRIVER_ENDPOINT: https://logging.googleapis.com
      STORAGE_ENDPOINT: https://storage.googleapis.com
      SYSCTL_OVERRIDES: net.core.somaxconn=2048,net.ipv4.tcp_rmem=4096 87380 16777216,net.ipv4.tcp_wmem=4096
        16384 16777216
      TPM_BOOTSTRAP_CERT: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURyRENDQWhTZ0F3SUJBZ0lSQUl1aHQvL1RJdWJKZXZXd3pjdnpGZ013RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa1ptVTRNell4WVdFdE5UUmxaaTAwWXpCaExXRTVNak10TlRKak56RmlZVFkxTmpGaQpNQjRYRFRJME1EZ3pNREUxTURRME0xb1hEVEk1TURneU9URTFNRFkwTTFvd0hERWFNQmdHQTFVRUF4TVJhM1ZpClpXeGxkQzFpYjI5MGMzUnlZWEF3Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRQ24Kd01TUHdkRjE0SWhZaElHZ1MvYnppK0sva2E0Z25NVWF2M1pSWFh0LzNpaktqSzdRNWpwTTRHZ3dVOVpndXZIbwpvQUlOdnF5aVo5VFVEMldVdmthTlhURERETFNwK3FCMEpsK2YwR25nK0Y5ZndKdCtpTnVoT1ppeGtKZldVUmU0CmliRnY5bWhXRmsyZUYwc05jcEFvekNuYkFEM2djQjlpQlJ6ak5maXFuTVAyNWFCRDJ0U2I4RXNIVXBOMzJTMGMKQitMRXQ4SFE0bzlkeisxalVDdlg0WTVFKzBrZFRDeSsrN1dJWmdBUUFNSUFBRlpYNzdlNWJFbm5Nd1VyRXh3RwpMNWdLNXVCbXBxdWNFRzRSdXAvTDFieDlBOThLKzYwSmxKTENZU01aMFhWaW9LZ0R4aktkeWdabHJmOEtYMDRVClk0cEloNitLRGYydmpQQUFnVGRSQWdNQkFBR2pWakJVTUE0R0ExVWREd0VCL3dRRUF3SUZvREFUQmdOVkhTVUUKRERBS0JnZ3JCZ0VGQlFjREFqQU1CZ05WSFJNQkFmOEVBakFBTUI4R0ExVWRJd1FZTUJhQUZDcVhhUFUwUWRQWQp3M0ZTL3pTTldpK0xhUFBOTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCZ1FESlVQODFpREFQNXdNR244VVUrOVNyCit2SHlSYkwveU1BYW8vNXA5TXQ0bW5YbWVpSVdlaXV0UUYwVjJxdFc3cXprUmNBUUhxQU9jMk5EOFBaU1Y5Q20KL1RmdjdJVnc0RmtwbTlvTTVWL3R6SDlaVEh2U2l1Z2RCTDdGVGRFYUNJVWFNWkZGTGk4MHRRUWIxb3lVMFkvRQpHQVgrL085dkFsUmUydk8wdGpZSk84a2ZFQysweGlyRjQvaklNV2FySUJTaDFaYkNkN0lETjVHR083Qjd5NU5UClhQME9NeWdselB4cW5zb2RWYXhzYjFlK28wWThPMEZJaVcvS3ZuZi9hY3laa2U0cUlZVHQ0WGVQMkhMWjZOMG0KcjBmYzNUMndIZlhRbVd5Rms3K3JwK2NZZ0t4U3lnWkF0WGwxRmhxcmJlOUJsNUl5UFNlanFZMi9qMno4UjgvOQpzTEtnNDF4aTlLaFhvY2VCaEVGc001azQwc2I3Y3doeHBOazlnZVhGWXhJWWtUUmlRYXcvWUtzd2lHdmpLRjFECmNkeGs0Ykk5eGlxUFBQL2ZLSWk4L3pMZE9Nb3QvNXljSGFVb3lPa0ZTQzErWXNnZEl3NzlYdkpNOFdZeFd2aHMKbC9KZmN6NCtYMU1xUk5GU2ZUTGozbUJ0MzdaMzhPRzBSNzBQa253K0ZNZz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
      TPM_BOOTSTRAP_KEY: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBcDhERWo4SFJkZUNJV0lTQm9FdjI4NHZpdjVHdUlKekZHcjkyVVYxN2Y5NG95b3l1CjBPWTZUT0JvTUZQV1lMcng2S0FDRGI2c29tZlUxQTlsbEw1R2pWMHd3d3kwcWZxZ2RDWmZuOUJwNFBoZlg4Q2IKZm9qYm9UbVlzWkNYMWxFWHVJbXhiL1pvVmhaTm5oZExEWEtRS013cDJ3QTk0SEFmWWdVYzR6WDRxcHpEOXVXZwpROXJVbS9CTEIxS1RkOWt0SEFmaXhMZkIwT0tQWGMvdFkxQXIxK0dPUlB0SkhVd3N2dnUxaUdZQUVBRENBQUJXClYrKzN1V3hKNXpNRkt4TWNCaStZQ3ViZ1pxYXJuQkJ1RWJxZnk5VzhmUVBmQ3Z1dENaU1N3bUVqR2RGMVlxQ28KQThZeW5jb0daYTMvQ2w5T0ZHT0tTSWV2aWczOXI0endBSUUzVVFJREFRQUJBb0lCQUFDOFNFc0JEelFKeEtTWgpZQ0FkeW5xNE5aNzFaVGdMWXBTQ3htS3c4RHV0U1FIVkFCSGhFSWNKd2lzdXZaVTFwMGlIMEdVb1hZVm1HSGx5CjM5VWp5R3k4NklaOUVIQmhBdXhxRy8wNERWN0pJcWMrMFpwZndKRnREbzJvdnFHdFFBSUtjeXdKMDl5Y3d4WmIKQlI4MytMTXFiS2M0ZkdKTU1PR3pJclNlKzBvZTNWWkg3aXlXZ1l2OHZVNFRaamo4aHJtRjJFU0dhZU8ydXVUOAoxeXIrSk9XejZDSUdYVlNhRXJBRUpIQjMzYVlrTjcyeDFGRHRVVXZiaGtOeGhHRjUxL0MzUWxwZndzNmk5V1QzCmhVR2VVdWhMOUNSaUpCVDltN3ZRYndDb2FtL0lHemRTejVwd3pheEpRRUYreXVUbm5GUEsrOFBHaW9WRnk2Q1gKRVJodzhXa0NnWUVBNStlL2k3WTlTTnNMWG9Zdm9yYXYyL0REMDdaWmtpUEttcW5hSDVxd05NcE5abUVJZVdJVwpGMDNXc2RSNHBwSkZBNHZsREtTNFBvcUkrV0U4ejZIMEJhZlFpQndCVFowQzg5WUNTOWFSbCt6MjRkeWdyTjY4CjBQUTRQdGMwUzZkZTJ1M0FxVDlIQXMySUx1ZkhNcEllWDdhUnNQWVptZkJ2bkJSeEUyQ3BmdThDZ1lFQXVTNncKRWJjdVdwdlFLKzAwZmw1OVV1Zzc3Zzd5NXhrODFYbGt2TFVLK2lqSFlpai8yL0FEQ3F2TlM1OTEyNUJEM2dNSwpwYTlpb2s3VEsyM04rZGtiY3grSHNBbUdGSU1xaFZwVGJkYVBVWkJMS0xyZEk0RGRaYzN2ZjM1blExK05DWEZKCmZWc0FrZ2tNZnV0eUNMcnNGWUY2VmZrUCtVRnVEK09NWnR6OHJiOENnWUFpWUgxSmhhdFNDSDZIOVpaTUpZNnUKS09PdWw2SnhnbksvT0p5SUFOTk1FQTBuTncwZGlVZkREcHZiNHFZNzh3VGVBTGZraHVwMUF1NUpJWHYxUDRtLwo2TitGdmJrSHUxVzd0YWJEZlR3NTdEdXd3WmJqNldUT0NOWHBvdGN5dTgzWTRGT21BeVpRcVEwZC91Zk5mRkdhCldLTUNPNGtTQTgxWHNzUU1YbERoNndLQmdHc3lCSWZzd3U5K2ZLM0EzUDg5MFV3WjFQOUVOZ1hpelIxQjdUZHoKa1l3bjZPc0Frc09ORnlXcE4rakx3Tnk5a1J2R0pQYXVKT21SdVpuTk1VdXRDci9FZzdZNmZSd0lwYWVXRnU5aApJWXQwZkoxeU5pcWtJUVVhaGNZR3RONENSTkV2ZS93Tm5ySHFmUXBIWHJhQkJjS1pOZWpvaVArZmlZZTNFQUpICmNCbGZBb0dCQUxrRUtTekVXcWN3aFBKOUpuMEhiSG1SdWNzYlhtM083SzQrRng4TTlVbmZyM1gxSkE2YkFUYlAKV1dyWURoWUdjV3hLNTYyaC96UkxjVzBYTkg4cGFXb05tb1R5WC9MbGJkc0crTnZ6eVhpNU0rWTF1Um1rSzlDRApqa0dGRzJjelNqZ20rNjgrTU5OaEVGTUZMdk1FYlhjTTVaVy9HOVliY2pidW54TzR6VHZqCi0tLS0tRU5EIFJTQSBQUklWQVRFIEtFWS0tLS0tCg==
      VOLUME_PLUGIN_DIR: /home/kubernetes/flexvolume
      ZONE: us-central1-a
  - key: cluster-uid
    value: 1abef528b40f440d9f953e7a27309828c2c0f9f2578c45c69565d31340febe0a
  - key: cluster-location
    value: us-central1-a
  kind: compute#metadata
name: gke-gpu-cluster-16-default-pool-b92275cf-glwr
networkInterfaces:
- accessConfigs:
  - kind: compute#accessConfig
    name: external-nat
    natIP: 35.225.164.99
    networkTier: PREMIUM
    type: ONE_TO_ONE_NAT
  aliasIpRanges:
  - ipCidrRange: 10.40.5.0/24
    subnetworkRangeName: gke-gpu-cluster-16-pods-1abef528
  fingerprint: DzsKLCyLvZk=
  kind: compute#networkInterface
  name: nic0
  network: https://www.googleapis.com/compute/v1/projects/converged-computing/global/networks/mtu9k
  networkIP: 10.128.0.74
  nicType: GVNIC
  stackType: IPV4_ONLY
  subnetwork: https://www.googleapis.com/compute/v1/projects/converged-computing/regions/us-central1/subnetworks/mtu9k
networkPerformanceConfig:
  totalEgressBandwidthTier: DEFAULT
satisfiesPzi: false
scheduling:
  automaticRestart: true
  onHostMaintenance: TERMINATE
  preemptible: false
  provisioningModel: STANDARD
selfLink: https://www.googleapis.com/compute/v1/projects/converged-computing/zones/us-central1-a/instances/gke-gpu-cluster-16-default-pool-b92275cf-glwr
serviceAccounts:
- email: 248370210276-compute@developer.gserviceaccount.com
  scopes:
  - https://www.googleapis.com/auth/devstorage.read_only
  - https://www.googleapis.com/auth/logging.write
  - https://www.googleapis.com/auth/monitoring
  - https://www.googleapis.com/auth/service.management.readonly
  - https://www.googleapis.com/auth/servicecontrol
  - https://www.googleapis.com/auth/trace.append
shieldedInstanceConfig:
  enableIntegrityMonitoring: true
  enableSecureBoot: false
  enableVtpm: true
shieldedInstanceIntegrityPolicy:
  updateAutoLearnPolicy: true
startRestricted: false
status: RUNNING
tags:
  fingerprint: GRR92KKmtFg=
  items:
  - gke-gpu-cluster-16-1abef528-node
zone: https://www.googleapis.com/compute/v1/projects/converged-computing/zones/us-central1-a
